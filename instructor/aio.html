<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Introduction to dMRI: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="../assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="../assets/styles.css">
<script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../favicons/incubator/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicons/incubator/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../favicons/incubator/favicon-16x16.png">
<link rel="manifest" href="../favicons/incubator/site.webmanifest">
<link rel="mask-icon" href="../favicons/incubator/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="white">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="black">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo.svg"><span class="badge text-bg-danger">
          <abbr title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.">
            <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
              Pre-Alpha
            </a>
            <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text">
<li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul>
</li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='../aio.html';">Learner View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Introduction to dMRI
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Introduction to dMRI
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<hr>
<li><a class="dropdown-item" href="discuss.html">Discussion</a></li>
<li><a class="dropdown-item" href="reference.html">Glossary</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="../instructor/aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Introduction to dMRI
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text">
<li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul>
</li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../aio.html">Learner View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="introduction.html">1. Introduction to Diffusion MRI data</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="preprocessing.html">2. Preprocessing dMRI data</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="local_orientation_reconstruction.html">3. Local fiber orientation reconstruction</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="diffusion_tensor_imaging.html">4. Diffusion Tensor Imaging (DTI)</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="constrained_spherical_deconvolution.html">5. Constrained Spherical Deconvolution (CSD)</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="tractography.html">6. Tractography</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="local_tractography.html">7. Local tractography</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="deterministic_tractography.html">8. Deterministic tractography</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="probabilistic_tractography.html">9. Probabilistic tractography</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr>
<li><a class="dropdown-item" href="discuss.html">Discussion</a></li>
<li><a class="dropdown-item" href="reference.html">Glossary</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources">
<a href="../instructor/aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-introduction"><p>Content from <a href="introduction.html">Introduction to Diffusion MRI data</a></p>
<hr>
<p>Last updated on 2024-02-29 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-dMRI/edit/main/episodes/introduction.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 25 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How is dMRI data represented?</li>
<li>What is diffusion weighting?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Representation of diffusion data and associated gradients</li>
<li>Learn about diffusion gradients</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="diffusion-weighted-imaging-dwi">Diffusion Weighted Imaging (DWI)<a class="anchor" aria-label="anchor" href="#diffusion-weighted-imaging-dwi"></a>
</h2>
<hr class="half-width">
<p>Diffusion MRI is a popular technique to study the brain’s white
matter. To do so, MRI sequences which are sensitive to the random,
microscropic motion (i.e. diffusion) of water protons are used. The
diffusion of water within biological structures, such as the brain, are
often restricted due to barriers (e.g. cell membranes), resulting in a
preferred direction of diffusion (anisotropy). A typical diffusion MRI
scan will acquire multiple volumes with varying magnetic fields
(i.e. diffusion gradients) which are sensitive to diffusion along a
particular direction and result in diffusion-weighted images (DWI).
Water diffusion that is occurring along the same direction as the
diffusion gradient results in an attenuated signal. Images with no
diffusion weighting (i.e. no diffusion gradient) are also acquired as
part of the acquisition protocol. With further processing (to be
discussed later in the lesson), the acquired images can provide
measurements which are related to the microscopic properties of brain
tissue. DWI has been used extensively to diagnose stroke, assess white
matter damage in many different kinds of diseases, provide insights into
the white matter connectivity, and much more!</p>
<p><img src="../fig/introduction/diffusion_directions.png" alt="Diffusion along different directions" class="figure"><br>
Diffusion along X, Y, and Z directions. The signal in the left/right
oriented corpus callosum is lowest when measured along X, while the
signal in the inferior/superior oriented corticospinal tract is lowest
when measured along Z.</p>
</section><section><h2 class="section-heading" id="b-values-b-vectors">b-values &amp; b-vectors<a class="anchor" aria-label="anchor" href="#b-values-b-vectors"></a>
</h2>
<hr class="half-width">
<p>In addition to the acquired diffusion images, two files are collected
as part of the diffusion dataset, known as the b-vectors and b-values.
The b-value (file suffix <code>.bval</code>) is the
diffusion-sensitizing factor, and reflects the timing and strength of
the diffusion gradients. A larger b-value means our DWI signal will be
more sensitive to the diffusion of water. The b-vector (file suffix
<code>.bvec</code>) corresponds to the direction with which diffusion
was measured. Together, these two files define the diffusion MRI
measurement as a set of gradient directions and corresponding
amplitudes, and are necessary to calculate useful measures of the
microscopic properties. The DWI acquisition process is thus:</p>
<ol style="list-style-type: decimal">
<li>Pick a direction to measure diffusion along (i.e. pick the diffusion
gradient direction). This is recorded in the <code>.bvec</code>
file.</li>
<li>Pick a strength of the magnetic gradient. This is recorded in the
<code>.bval</code> file.</li>
<li>Acquire the MRI with these settings to examine water diffusion along
the chosen direction. This is the DWI volume.</li>
<li>Thus, for every DWI volume we have an associated b-value and
b-vector which tells us how we measured the diffusion.</li>
</ol></section><section><h2 class="section-heading" id="dataset">Dataset<a class="anchor" aria-label="anchor" href="#dataset"></a>
</h2>
<hr class="half-width">
<p>For the rest of this lesson, we will make use of a subset of a
publicly available dataset, ds000221, originally hosted at <a href="https://openneuro.org/datasets/ds000221/versions/1.0.0" class="external-link">openneuro.org</a>.
The dataset is structured according to the Brain Imaging Data Structure
(<a href="https://bids-specification.readthedocs.io/en/etable/" class="external-link">BIDS</a>).
Please check the <a href="https://carpentries-incubator.github.io/SDC-BIDS-dMRI/setup.html" class="external-link">BIDS-dMRI
Setup page</a> to download the dataset.</p>
<p>Below is a tree diagram showing the folder structure of a single MR
subject and session within ds000221. This was obtained by using the bash
command <code>tree<code>.</code></code></p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="ex">tree</span> <span class="st">'../data/ds000221'</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>../data/ds000221
├── .bidsignore
├── CHANGES
├── dataset_description.json
├── participants.tsv
├── README
├── derivatives/
├── sub-010001/
└── sub-010002/
    ├── ses-01/
    │    ├── anat
    │    │    ├── sub-010002_ses-01_acq-lowres_FLAIR.json
    │    │    ├── sub-010002_ses-01_acq-lowres_FLAIR.nii.gz
    │    │    ├── sub-010002_ses-01_acq-mp2rage_defacemask.nii.gz
    │    │    ├── sub-010002_ses-01_acq-mp2rage_T1map.nii.gz
    │    │    ├── sub-010002_ses-01_acq-mp2rage_T1w.nii.gz
    │    │    ├── sub-010002_ses-01_inv-1_mp2rage.json
    │    │    ├── sub-010002_ses-01_inv-1_mp2rage.nii.gz
    │    │    ├── sub-010002_ses-01_inv-2_mp2rage.json
    │    │    ├── sub-010002_ses-01_inv-2_mp2rage.nii.gz
    │    │    ├── sub-010002_ses-01_T2w.json
    │    │    └── sub-010002_ses-01_T2w.nii.gz
    │    ├── dwi
    │    │    ├── sub-010002_ses-01_dwi.bval
    │    │    │── sub-010002_ses-01_dwi.bvec
    │    │    │── sub-010002_ses-01_dwi.json
    │    │    └── sub-010002_ses-01_dwi.nii.gz
    │    ├── fmap
    │    │    ├── sub-010002_ses-01_acq-GEfmap_run-01_magnitude1.json
    │    │    ├── sub-010002_ses-01_acq-GEfmap_run-01_magnitude1.nii.gz
    │    │    ├── sub-010002_ses-01_acq-GEfmap_run-01_magnitude2.json
    │    │    ├── sub-010002_ses-01_acq-GEfmap_run-01_magnitude2.nii.gz
    │    │    ├── sub-010002_ses-01_acq-GEfmap_run-01_phasediff.json
    │    │    ├── sub-010002_ses-01_acq-GEfmap_run-01_phasediff.nii.gz
    │    │    ├── sub-010002_ses-01_acq-SEfmapBOLDpost_dir-AP_epi.json
    │    │    ├── sub-010002_ses-01_acq-SEfmapBOLDpost_dir-AP_epi.nii.gz
    │    │    ├── sub-010002_ses-01_acq-SEfmapBOLDpost_dir-PA_epi.json
    │    │    ├── sub-010002_ses-01_acq-SEfmapBOLDpost_dir-PA_epi.nii.gz
    │    │    ├── sub-010002_ses-01_acq-sefmapBOLDpre_dir-AP_epi.json
    │    │    ├── sub-010002_ses-01_acq-sefmapBOLDpre_dir-AP_epi.nii.gz
    │    │    ├── sub-010002_ses-01_acq-sefmapBOLDpre_dir-PA_epi.json
    │    │    ├── sub-010002_ses-01_acq-sefmapBOLDpre_dir-PA_epi.nii.gz
    │    │    ├── sub-010002_ses-01_acq-SEfmapBOLDpost_dir-AP_epi.json
    │    │    ├── sub-010002_ses-01_acq-SEfmapBOLDpost_dir-AP_epi.nii.gz
    │    │    ├── sub-010002_ses-01_acq-SEfmapBOLDpost_dir-PA_epi.json
    │    │    ├── sub-010002_ses-01_acq-SEfmapBOLDpost_dir-PA_epi.nii.gz
    │    │    ├── sub-010002_ses-01_acq-SEfmapDWI_dir-AP_epi.json
    │    │    ├── sub-010002_ses-01_acq-SEfmapDWI_dir-AP_epi.nii.gz
    │    │    ├── sub-010002_ses-01_acq-SEfmapDWI_dir-PA_epi.json
    │    │    └── sub-010002_ses-01_acq-SEfmapDWI_dir-PA_epi.nii.gz
    │    └── func
    │    │    ├── sub-010002_ses-01_task-rest_acq-AP_run-01_bold.json
    │    │    └── sub-010002_ses-01_task-rest_acq-AP_run-01_bold.nii.gz
    └── ses-02/</code></pre>
</div>
</section><section><h2 class="section-heading" id="querying-a-bids-dataset">Querying a BIDS Dataset<a class="anchor" aria-label="anchor" href="#querying-a-bids-dataset"></a>
</h2>
<hr class="half-width">
<p><a href="https://bids-standard.github.io/pybids/" class="external-link">pybids</a> is a
Python package for querying, summarizing and manipulating the BIDS
folder structure. We will make use of <code>pybids</code> to query the
necessary files.</p>
<p>Let’s first pull the metadata from its associated JSON file
(dictionary-like data storage) using the <code>get_metadata()</code>
function for the first run.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">from</span> bids.layout <span class="im">import</span> BIDSLayout</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>?BIDSLayout</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>layout <span class="op">=</span> BIDSLayout(<span class="st">"../data/ds000221"</span>, validate<span class="op">=</span><span class="va">False</span>)</span></code></pre>
</div>
<p>Now that we have a layout object, we can work with a BIDS dataset!
Let’s extract the metadata from the dataset.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>dwi <span class="op">=</span> layout.get(subject<span class="op">=</span><span class="st">'010006'</span>, suffix<span class="op">=</span><span class="st">'dwi'</span>, extension<span class="op">=</span><span class="st">'.nii.gz'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>layout.get_metadata(dwi)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>{'EchoTime': 0.08,
 'EffectiveEchoSpacing': 0.000390001,
 'FlipAngle': 90,
 'ImageType': ['ORIGINAL', 'PRIMARY', 'DIFFUSION', 'NON'],
 'MagneticFieldStrength': 3,
 'Manufacturer': 'Siemens',
 'ManufacturersModelName': 'Verio',
 'MultibandAccelerationFactor': 2,
 'ParallelAcquisitionTechnique': 'GRAPPA',
 'ParallelReductionFactorInPlane': 2,
 'PartialFourier': '7/8',
 'PhaseEncodingDirection': 'j-',
 'RepetitionTime': 7,
 'TotalReadoutTime': 0.04914}</code></pre>
</div>
</section><section><h2 class="section-heading" id="diffusion-imaging-in-python-dipy">Diffusion Imaging in Python (<a href="https://dipy.org" class="external-link">DIPY</a>)<a class="anchor" aria-label="anchor" href="#diffusion-imaging-in-python-dipy"></a>
</h2>
<hr class="half-width">
<p>For this lesson, we will use the <code>DIPY</code> (Diffusion Imaging
in Python) package for processing and analysing diffusion MRI.</p>
<div class="section level3">
<h3 id="why-dipy">Why <code>DIPY</code>?<a class="anchor" aria-label="anchor" href="#why-dipy"></a>
</h3>
<ul>
<li>Fully free and open source.</li>
<li>Implemented in Python. Easy to understand, and easy to use.</li>
<li>Implementations of many state-of-the art algorithms.</li>
<li>High performance. Many algorithms implemented in <a href="https://cython.org/" class="external-link">Cython</a>.</li>
</ul>
</div>
<div class="section level3">
<h3 id="defining-a-measurement-gradienttable">Defining a measurement: <code>GradientTable</code>
<a class="anchor" aria-label="anchor" href="#defining-a-measurement-gradienttable"></a>
</h3>
<p><code>DIPY</code> has a built-in function that allows us to read in
<code>bval</code> and <code>bvec</code> files named
<code>read_bvals_bvecs</code> under the <code>dipy.io.gradients</code>
module. Let’s first grab the path to our gradient directions and
amplitude files and load them into memory.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>bvec <span class="op">=</span> layout.get_bvec(dwi)</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>bval <span class="op">=</span> layout.get_bval(dwi)</span></code></pre>
</div>
<p>Now that we have the necessary diffusion files, let’s explore the
data!</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="im">import</span> nibabel <span class="im">as</span> nib</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>data <span class="op">=</span> nib.load(dwi).get_fdata()</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>data.shape</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(128, 128, 88, 67)</code></pre>
</div>
<p>We can see that the data is 4 dimensional. The 4th dimension
represents the different diffusion directions we are sensitive to. Next,
let’s take a look at a slice.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>x_slice <span class="op">=</span> data[<span class="dv">58</span>, :, :, <span class="dv">0</span>]</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>y_slice <span class="op">=</span> data[:, <span class="dv">58</span>, :, <span class="dv">0</span>]</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>z_slice <span class="op">=</span> data[:, :, <span class="dv">30</span>, <span class="dv">0</span>]</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>slices <span class="op">=</span> [x_slice, y_slice, z_slice]</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="bu">len</span>(slices))</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a><span class="cf">for</span> i, _slice <span class="kw">in</span> <span class="bu">enumerate</span>(slices):</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>    axes[i].imshow(_slice.T, cmap<span class="op">=</span><span class="st">"gray"</span>, origin<span class="op">=</span><span class="st">"lower"</span>)</span></code></pre>
</div>
<figure><img src="../fig/introduction/dwi_slice.png" alt="DWI slice" class="figure mx-auto d-block"></figure><p>We can also see how the diffusion gradients are represented. This is
plotted on a sphere, the further away from the center of the sphere, the
stronger the diffusion gradient (increased sensitivity to
diffusion).</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>bvec_txt <span class="op">=</span> np.genfromtxt(bvec)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>ax.scatter(bvec_txt[<span class="dv">0</span>], bvec_txt[<span class="dv">1</span>], bvec_txt[<span class="dv">2</span>])</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/introduction/diffusion_gradient.png" alt="Diffusion gradient sphere" class="figure mx-auto d-block"></figure><p>The files associated with the diffusion gradients need to converted
to a <code>GradientTable</code> object to be used with
<code>DIPY</code>. A <code>GradientTable</code> object can be
implemented using the <code>dipy.core.gradients</code> module. The input
to the <code>GradientTable</code> should be our the values for our
gradient directions and amplitudes we read in.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="im">from</span> dipy.io.gradients <span class="im">import</span> read_bvals_bvecs</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="im">from</span> dipy.core.gradients <span class="im">import</span> gradient_table</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>gt_bvals, gt_bvecs <span class="op">=</span> read_bvals_bvecs(bval, bvec)</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>gtab <span class="op">=</span> gradient_table(gt_bvals, gt_bvecs)</span></code></pre>
</div>
<p>We will need this gradient table later on to process and model our
data!</p>
<p>There is also a built-in function for gradient tables,
<code>b0s_mask</code> that can be used to separate diffusion weighted
measurements from non-diffusion weighted measurements (<span class="math inline">\(b = 0 s/mm^2\)</span>, commonly referred to as the
B0 volume or image). It is important to know where our diffusion
weighted free measurements are as we need them for registration in our
preprocessing (our next notebook). <code>gtab.b0s_mask</code> shows that
this is our first volume of our dataset.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>gtab.b0s_mask</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>array([ True, False, False, False, False, False, False, False, False,
       False, False,  True, False, False, False, False, False, False,
       False, False, False, False,  True, False, False, False, False,
       False, False, False, False, False, False,  True, False, False,
       False, False, False, False, False, False, False, False,  True,
       False, False, False, False, False, False, False, False, False,
       False,  True, False, False, False, False, False, False, False,
       False, False, False,  True])</code></pre>
</div>
<p>We will also extract the vector corresponding to only diffusion
weighted measurements (or equivalently, return everything that is not a
<span class="math inline">\(b = 0 s/mm^2\)</span>)!</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>gtab.bvecs[<span class="op">~</span>gtab.b0s_mask]</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>array([[-2.51881e-02, -3.72268e-01,  9.27783e-01],
       [ 9.91276e-01, -1.05773e-01, -7.86433e-02],
       [-1.71007e-01, -5.00324e-01, -8.48783e-01],
       [-3.28334e-01, -8.07475e-01,  4.90083e-01],
       [ 1.59023e-01, -5.08209e-01, -8.46425e-01],
       [ 4.19677e-01, -5.94275e-01,  6.86082e-01],
       [-8.76364e-01, -4.64096e-01,  1.28844e-01],
       [ 1.47409e-01, -8.01322e-02,  9.85824e-01],
       [ 3.50020e-01, -9.29191e-01, -1.18704e-01],
       [ 6.70475e-01,  1.96486e-01,  7.15441e-01],
       [-6.85569e-01,  2.47048e-01,  6.84808e-01],
       [ 3.21619e-01, -8.24329e-01,  4.65879e-01],
       [-8.35634e-01, -5.07463e-01, -2.10233e-01],
       [ 5.08740e-01, -8.43979e-01,  1.69950e-01],
       [-8.03836e-01, -3.83790e-01,  4.54481e-01],
       [-6.82578e-02, -7.53445e-01, -6.53959e-01],
       [-2.07898e-01, -6.27330e-01,  7.50490e-01],
       [ 9.31645e-01, -3.38939e-01,  1.30988e-01],
       [-2.04382e-01, -5.95385e-02,  9.77079e-01],
       [-3.52674e-01, -9.31125e-01, -9.28787e-02],
       [ 5.11906e-01, -7.06485e-02,  8.56132e-01],
       [ 4.84626e-01, -7.73448e-01, -4.08554e-01],
       [-8.71976e-01, -2.40158e-01, -4.26593e-01],
       [-3.53191e-01, -3.41688e-01,  8.70922e-01],
       [-6.89136e-01, -5.16115e-01, -5.08642e-01],
       [ 7.19336e-01, -5.25068e-01, -4.54817e-01],
       [ 1.14176e-01, -6.44483e-01,  7.56046e-01],
       [-5.63224e-01, -7.67654e-01, -3.05754e-01],
       [-5.31237e-01, -1.29342e-02,  8.47125e-01],
       [ 7.99914e-01, -7.30043e-02,  5.95658e-01],
       [-1.43792e-01, -9.64620e-01,  2.20979e-01],
       [ 9.55196e-01, -5.23107e-02,  2.91314e-01],
       [-3.64423e-01,  2.53394e-01,  8.96096e-01],
       [ 6.24566e-01, -6.44762e-01,  4.40680e-01],
       [-3.91818e-01, -7.09411e-01, -5.85845e-01],
       [-5.21993e-01, -5.74810e-01,  6.30172e-01],
       [ 6.56573e-01, -7.41002e-01, -1.40812e-01],
       [-6.68597e-01, -6.60616e-01,  3.41414e-01],
       [ 8.20224e-01, -3.72360e-01,  4.34259e-01],
       [-2.05263e-01, -9.02465e-01, -3.78714e-01],
       [-6.37020e-01, -2.83529e-01,  7.16810e-01],
       [ 1.37944e-01, -9.14231e-01, -3.80990e-01],
       [-9.49691e-01, -1.45434e-01,  2.77373e-01],
       [-7.31922e-03, -9.95911e-01, -9.00386e-02],
       [-8.14263e-01, -4.20783e-02,  5.78969e-01],
       [ 1.87418e-01, -9.63210e-01,  1.92618e-01],
       [ 3.30434e-01,  1.92714e-01,  9.23945e-01],
       [ 8.95093e-01, -2.18266e-01, -3.88805e-01],
       [ 3.11358e-01, -3.49170e-01,  8.83819e-01],
       [-6.86317e-01, -7.27289e-01, -4.54356e-03],
       [ 4.92805e-01, -5.14280e-01, -7.01897e-01],
       [-8.03482e-04, -8.56796e-01,  5.15655e-01],
       [-4.77664e-01, -4.45734e-01, -7.57072e-01],
       [ 7.68954e-01, -6.22151e-01,  1.47095e-01],
       [-1.55099e-02,  2.22329e-01,  9.74848e-01],
       [-9.74410e-01, -2.11297e-01, -7.66740e-02],
       [ 2.56251e-01, -7.33793e-01, -6.29193e-01],
       [ 6.24656e-01, -3.42071e-01,  7.01992e-01],
       [-4.61411e-01, -8.64670e-01,  1.98612e-01],
       [ 8.68547e-01, -4.66754e-01, -1.66634e-01]])</code></pre>
</div>
<p>In the next few notebooks, we will talk more about preprocessing the
diffusion weighted images, reconstructing the diffusion tensor model,
and reconstruction axonal trajectories via tractography.</p>
<div id="exercise-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise-1" class="callout-inner">
<h3 class="callout-title">Exercise 1</h3>
<div class="callout-content">
<p>Get a list of <strong>all</strong> diffusion data in NIfTI file
format</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>dwi_data <span class="op">=</span> layout.get(suffix<span class="op">=</span><span class="st">'dwi'</span>, extension<span class="op">=</span><span class="st">'.nii.gz'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>dMRI data is represented as a 4-dimensional image (x,y,z,diffusion
directional sensitivity)</li>
<li>dMRI data is sensitive to a particular direction of diffusion
motion. Due to this sensitivity, each volume of the 4D image is
sensitive to a particular direction</li>
</ul>
</div>
</div>
</div>
<!-- Workshop-specific links -->
</div>
</section></section><section id="aio-preprocessing"><p>Content from <a href="preprocessing.html">Preprocessing dMRI data</a></p>
<hr>
<p>Last updated on 2024-02-18 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-dMRI/edit/main/episodes/preprocessing.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the standard preprocessing steps?</li>
<li>How do we register with an anatomical image?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the common preprocessing steps</li>
<li>Learn to register diffusion data</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="diffusion-preprocessing">Diffusion Preprocessing<a class="anchor" aria-label="anchor" href="#diffusion-preprocessing"></a>
</h2>
<hr class="half-width">
<p>Diffusion MRI data does not typically come off the scanner ready to
be analyzed, and there can be many things that might need to be
corrected before analysis. Diffusion preprocessing typically comprises
of a series of steps to perform the necessary corrections to the data.
These steps may vary depending on how the data is acquired. Some
consensus has been reached for certain preprocessing steps, while others
are still up for debate. The lesson will primarily focus on the
preprocessing steps where consensus has been reached. Preprocessing is
performed using a few well-known software packages (e.g. <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki" class="external-link">FSL</a>, <a href="https://github.com/ANTsX/ANTs" class="external-link">ANTs</a>. For the purposes of these
lessons, preprocessing steps requiring these software packages has
already been performed for the dataset <code>ds000221</code> and the
commands required for each step will be provided. This dataset contains
single shell diffusion data with 7 <span class="math inline">\(b = 0
s/mm^2\)</span> volumes (non-diffusion weighted) and 60 <span class="math inline">\(b = 1000 s/mm^2\)</span> volumes. In addition,
field maps (found in the <code>fmap</code> directory are acquired with
opposite phase-encoding directions).</p>
<p>To illustrate what the preprocessing step may look like, here is an
example preprocessing workflow from QSIPrep (Cieslak <em>et al</em>,
2020): <img src="../fig/preprocessing/preprocess_steps.jpg" alt="Preprocessing steps" class="figure"></p>
<p>dMRI has some similar challenges to fMRI preprocessing, as well as
some unique <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3366862/" class="external-link">ones</a>.</p>
<p>Our preprocesssing of this data will consist of following steps:</p>
<ol style="list-style-type: decimal">
<li>Brainmasking the diffusion data.</li>
<li>Applying <code>FSL</code> <code>topup</code> to correct for
susceptibility induced distortions.</li>
<li>
<code>FSL</code> Eddy current distortion correction.</li>
<li>Registration to T1w.</li>
</ol>
<p>The same subject (<code>sub-010006</code>) will be used throughout
the remainder of the lesson.</p>
<div class="section level3">
<h3 id="brainmasking">Brainmasking<a class="anchor" aria-label="anchor" href="#brainmasking"></a>
</h3>
<p>The first step to the preprocessing workflow is to create an
appropriate brainmask from the diffusion data! Start by first importing
the necessary modules and reading the diffusion data along with the
coordinate system (the affine)! We will also grab the anatomical T1w
image to use later on, as well as the second inversion from the
anatomical acquisition for brainmasking purposes.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> bids.layout <span class="im">import</span> BIDSLayout</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>layout <span class="op">=</span> BIDSLayout(<span class="st">"../../data/ds000221"</span>, validate<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>subj<span class="op">=</span><span class="st">'010006'</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co"># Diffusion data</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>dwi <span class="op">=</span> layout.get(subject<span class="op">=</span>subj, suffix<span class="op">=</span><span class="st">'dwi'</span>, extension<span class="op">=</span><span class="st">'.nii.gz'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="co"># Anatomical data</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>t1w <span class="op">=</span> layout.get(subject<span class="op">=</span>subj, suffix<span class="op">=</span><span class="st">'T1w'</span>, extension<span class="op">=</span><span class="st">'.nii.gz'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">import</span> nibabel <span class="im">as</span> nib</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>dwi <span class="op">=</span> nib.load(dwi)</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>dwi_affine <span class="op">=</span> dwi.affine</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>dwi_data <span class="op">=</span> dwi.get_fdata()</span></code></pre>
</div>
<p><code>DIPY</code>’s <code>segment.mask</code> module will be used to
create a brainmask from this. This module contains a function
<code>median_otsu</code>, which can be used to segment the brain and
provide a binary brainmask! Here, a brainmask will be created using the
first non-diffusion volume of the data. We will save this brainmask to
be used in our later future preprocessing steps. After creating the
brainmask, we will start to correct for distortions in our images.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="im">from</span> dipy.segment.mask <span class="im">import</span> median_otsu</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co"># vol_idx is a 1D-array containing the index of the first b0</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>dwi_brain, dwi_mask <span class="op">=</span> median_otsu(dwi_data, vol_idx<span class="op">=</span>[<span class="dv">0</span>])</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="co"># Create necessary folders to save mask</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>out_dir <span class="op">=</span> <span class="ss">f'../../data/ds000221/derivatives/uncorrected/sub-</span><span class="sc">{</span>subj<span class="sc">}</span><span class="ss">/ses-01/dwi/'</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="co"># Check to see if directory exists, if not create one</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(out_dir):</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>    os.makedirs(out_dir)</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>img <span class="op">=</span> nib.Nifti1Image(dwi_mask.astype(np.float32), dwi_affine)</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>nib.save(img, os.path.join(out_dir, <span class="ss">f"sub-</span><span class="sc">{</span>subj<span class="sc">}</span><span class="ss">_ses-01_brainmask.nii.gz"</span>))</span></code></pre>
</div>
<figure><img src="../fig/preprocessing/dwi_brainmask.png" alt="b0 brainmask" class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="fsl-topup">
<code>FSL</code> <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup" class="external-link"><code>topup</code></a>
<a class="anchor" aria-label="anchor" href="#fsl-topup"></a>
</h3>
<p>Diffusion images, typically acquired using spin-echo echo planar
imaging (EPI), are sensitive to non-zero off-resonance fields. One
source of these fields is from the susceptibility distribution of the
subjects head, otherwise known as susceptibility-induced off-resonance
field. This field is approximately constant for all acquired diffusion
images. As such, for a set of diffusion volumes, the
susceptibility-induced field will be consistent throughout. This is
mainly a problem due to geometric mismatches with the anatomical images
(e.g. T1w), which are typically unaffected by such distortions.</p>
<p><code>topup</code>, part of the <code>FSL</code> library, estimates
and attempts to correct the susceptibility-induced off-resonance field
by using 2 (or more) acquisitions, where the acquisition parameters
differ such that the distortion differs. Typically, this is done using
two acquisitions acquired with opposite phase-encoding directions, which
results in the same field creating distortions in opposing
directions.</p>
<p><img src="../fig/preprocessing/blip_up_blip_down.png" alt="Blip up and blip down pairs" class="figure"><br>
Opposite phase-encodings from two DWI</p>
<p>Here, we will make use of the two opposite phase-encoded acquisitions
found in the <code>fmap</code> directory of each subject. These are
acquired with a diffusion weighting of <span class="math inline">\(b = 0
s/mm^2\)</span>. Alternatively, if these are not available, one can also
extract and make use of the non-diffusion weighted images (assuming the
data is also acquired with opposite phase encoding directions).</p>
<p>First, we will merge the two files so that all of the volumes are in
1 file.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="fu">mkdir</span> <span class="at">-p</span> ../../data/ds000221/derivatives/uncorrected_topup/sub-010006/ses-01/dwi/work</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="ex">fslmerge</span> <span class="at">-t</span> ../../data/ds000221/derivatives/uncorrected_topup/sub-010006/ses-01/dwi/work/sub-010006_ses-01_acq-SEfmapDWI_epi.nii.gz ../../data/ds000221/sub-010006/ses-01/fmap/sub-010006_ses-01_acq-SEfmapDWI_dir-AP_epi.nii.gz ../../data/ds000221/sub-010006/ses-01/fmap/sub-010006_ses-01_acq-SEfmapDWI_dir-PA_epi.nii.gz</span></code></pre>
</div>
<p>Another file we will need to create is a text file containing the
information about how the volumes were acquired. Each line in this file
will pertain to a single volume in the merged file. The first 3 values
of each line refers to the acquisition direction, typically along the
y-axis (or anterior-posterior). The final value is the total readout
time (from center of first echo to center of final echo), which can be
determined from values contained within the associated JSON metadata
file (named “JSON sidecar file” within the BIDS specification). Each
line will look similar to <code>[x y z TotalReadoutTime]</code>. In this
case, the file, which we created, is contained within the
<code>pedir.txt</code> file in the derivative directory.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="ex">0</span> 1 0 0.04914</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="ex">0</span> 1 0 0.04914</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="ex">0</span> 1 0 0.04914</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="ex">0</span> <span class="at">-1</span> 0 0.04914</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="ex">0</span> <span class="at">-1</span> 0 0.04914</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="ex">0</span> <span class="at">-1</span> 0 0.04914</span></code></pre>
</div>
<p>With these two inputs, the next step is to make the call to
<code>topup</code> to estimate the susceptibility-induced field. Within
the call, a few parameters are used. Briefly:</p>
<ul>
<li>
<code>--imain</code> specifies the previously merged volume.</li>
<li>
<code>--datain</code> specifies the text file containing the
information regarding the acquisition.</li>
<li>
<code>--config=b02b0.cnf</code> makes use of a predefined config
file. supplied with <code>topup</code>, which contains parameters useful
to registering with good <span class="math inline">\(b = 0
s/mm^2\)</span> images.</li>
<li>
<code>--out</code> defines the output files containing the spline.
coefficients for the induced field, as well as subject movement
parameters.</li>
</ul>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="ex">topup</span> <span class="at">--imain</span><span class="op">=</span>../../data/ds000221/derivatives/topup/sub-010006/ses-01/dwi/work/sub-010006_ses-01_acq-SEfmapDWI_epi.nii.gz <span class="at">--datain</span><span class="op">=</span>../../data/ds000221/derivatives/topup/sub-010006/ses-01/dwi/work/pedir.txt <span class="at">--config</span><span class="op">=</span>b02b0.cnf <span class="at">--out</span><span class="op">=</span>../../data/ds000221/derivatives/topup/sub-010006/ses-01/dwi/work/topup</span></code></pre>
</div>
<p>Next, we can apply the correction to the entire diffusion weighted
volume by using <code>applytopup</code> Similar to <code>topup</code>, a
few parameters are used. Briefly:</p>
<ul>
<li>
<code>--imain</code> specifies the input diffusion weighted
volume.</li>
<li>
<code>--datain</code> again specifies the text file containing
information regarding the acquisition - same file previously used.</li>
<li>
<code>--inindex</code> specifies the index (comma separated list) of
the input image to be corrected.</li>
<li>
<code>--topup</code> name of field/movements (from previous topup
step.</li>
<li>
<code>--out</code> basename for the corrected output image.</li>
<li>
<code>--method</code> (optional) jacobian modulation (jac) or
least-squares resampling (lsr).</li>
</ul>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="ex">applytopup</span> <span class="at">--imain</span><span class="op">=</span>../../data/ds000221/sub-010006/ses-01/dwi/sub-010006_ses-01_dwi.nii.gz <span class="at">--datain</span><span class="op">=</span>../../data/ds000221/derivatives/topup/sub-010006/ses-01/dwi/work/pedir.txt <span class="at">--inindex</span><span class="op">=</span>1 <span class="at">--topup</span><span class="op">=</span>../../data/ds000221/derivatives/topup/sub-010006/ses-01/dwi/work/topup <span class="at">--out</span><span class="op">=</span>../../data/ds000221/derivatives/topup/sub-010006/ses-01/dwi/dwi <span class="at">--method</span><span class="op">=</span>jac</span></code></pre>
</div>
<figure><img src="../fig/preprocessing/dwi_topup.png" alt="Topup image" class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="fsl-eddy">
<code>FSL</code> <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy" class="external-link"><code>Eddy</code></a>
<a class="anchor" aria-label="anchor" href="#fsl-eddy"></a>
</h3>
<p>Another source of the non-zero off resonance fields is caused by the
rapid switching of diffusion weighting gradients, otherwise known as
eddy current-induced off-resonance fields. Additionally, the subject is
likely to move during the diffusion protocol, which may be lengthy.</p>
<p><code>eddy</code>, also part of the <code>FSL</code> library,
attempts to correct for both eddy current-induced fields and subject
movement by reading the gradient table and estimating the distortion
volume by volume. This tool is also able to optionally detect and
replace outlier slices.</p>
<p>Here, we will demonstrate the application of <code>eddy</code>
following the <code>topup</code> correction step, by making use of both
the uncorrected diffusion data, as well as estimated warpfield from the
<code>topup</code>. Additionally, a text file, which maps each of the
volumes to one of the corresponding acquisition directions from the
<code>pedir.txt</code> file will have to be created. Finally, similar to
<code>topup</code>, there are also a number of input parameters which
have to be specified:</p>
<ul>
<li>
<code>--imain</code> specifies the undistorted diffusion weighted
volume.</li>
<li>
<code>--mask</code> specifies the brainmask for the undistorted
diffusion weighted volume.</li>
<li>
<code>--acqp</code> specifies the the text file containing
information regarding the acquisition that was previously used in
<code>topup</code>.</li>
<li>
<code>--index</code> is the text file which maps each diffusion
volume to the corresponding acquisition direction.</li>
<li>
<code>--bvecs</code> specifies the bvec file to the undistorted
dwi.</li>
<li>
<code>--bvals</code> similarily specifies the bval file to the
undistorted dwi.</li>
<li>
<code>--topup</code> specifies the directory and distortion
correction files previously estimated by <code>topup</code>.</li>
<li>
<code>--out</code> specifies the prefix of the output files
following eddy correction.</li>
<li>
<code>--repol</code> is a flag, which specifies replacement of
outliers.</li>
</ul>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">mkdir</span> <span class="at">-p</span> ../../data/ds000221/derivatives/uncorrected_topup_eddy/sub-010006/ses-01/dwi/work</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co"># Create an index file mapping the 67 volumes in 4D dwi volume to the pedir.txt file</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="va">indx</span><span class="op">=</span><span class="st">""</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="kw">`</span><span class="fu">seq</span> 1 67<span class="kw">`;</span> <span class="cf">do</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>  <span class="va">indx</span><span class="op">=</span><span class="st">"</span><span class="va">$indx</span><span class="st"> 1"</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="cf">done</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="bu">echo</span> <span class="va">$indx</span> <span class="op">&gt;</span> ../../data/ds000221/derivatives/uncorrected_topup_eddy/sub-010006/ses-01/dwi/work/index.txt</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a><span class="ex">eddy</span> <span class="at">--imain</span><span class="op">=</span>../../data/ds000221/sub-010006/ses-01/dwi/sub-010006_ses-01_dwi.nii.gz <span class="at">--mask</span><span class="op">=</span>../../data/ds000221/derivatives/uncorrected/sub-010006/ses-01/dwi/sub-010006_ses-01_brainmask.nii.gz <span class="at">--acqp</span><span class="op">=</span>../../data/ds000221/derivatives/uncorrected_topup/sub-010006/ses-01/dwi/work/pedir.txt <span class="at">--index</span><span class="op">=</span>../../data/ds000221/derivatives/uncorrected_topup_eddy/sub-010006/ses-01/dwi/work/index.txt <span class="at">--bvecs</span><span class="op">=</span>../../data/ds000221/sub-010006/ses-01/dwi/sub-010006_ses-01_dwi.bvec <span class="at">--bvals</span><span class="op">=</span>../../data/ds000221/sub-010006/ses-01/dwi/sub-010006_ses-01_dwi.bval <span class="at">--topup</span><span class="op">=</span>../../data/ds000221/derivatives/uncorrected_topup/sub-010006/ses-01/dwi/work/topup <span class="at">--out</span><span class="op">=</span>../../data/ds000221/derivatives/uncorrected_topup_eddy/sub-010006/ses-01/dwi/dwi <span class="at">--repol</span></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="registration-with-t1w">Registration with T1w<a class="anchor" aria-label="anchor" href="#registration-with-t1w"></a>
</h3>
<p>The final step to our diffusion processing is registration to an
anatomical image (e.g. T1-weighted). This is important because the
diffusion data, typically acquired using echo planar imaging or EPI,
enables faster acquisitions at the cost of lower resolution and
introduction of distortions (as seen above). Registration with the
anatomical image not only helps to correct for some distortions, it also
provides us with a higher resolution, anatomical reference.</p>
<p>First, we will create a brainmask of the anatomical image using the
anatomical acquisition (e.g. T1-weighted). To do this, we will use
<code>FSL</code> <code>bet</code> twice. The first call to
<code>bet</code> will create a general skullstripped brain. Upon
inspection, we can note that there is still some residual areas of the
image which were included in the first pass. Calling <code>bet</code> a
second time, we get a better outline of the brain and brainmask, which
we can use for further processing.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="fu">mkdir</span> <span class="at">-p</span> ../../data/ds000221/derivatives/uncorrected/sub-010006/ses-01/anat</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="ex">bet</span> ../../data/ds000221/sub-010006/ses-01/anat/sub-010006_ses-01_inv-2_mp2rage.nii.gz ../../data/ds000221/derivatives/uncorrected/sub-010006/ses-01/anat/sub-010006_ses-01_space-T1w_broadbrain <span class="at">-f</span> 0.6</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="ex">bet</span> ../../data/ds000221/derivatives/uncorrected/sub-010006/ses-01/anat/sub-010006_ses-01_space-T1w_broadbrain ../../data/ds000221/derivatives/uncorrected/sub-010006/ses-01/anat/sub-010006_ses-01_space-T1w_brain <span class="at">-f</span> 0.4 <span class="at">-m</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="fu">mv</span> ../../data/ds000221/derivatives/uncorrected/sub-010006/ses-01/anat/sub-010006_ses-01_space-T1w_brain_mask.nii.gz ../../data/ds000221/derivatives/uncorrected/sub-010006/ses-01/anat/sub-010006_ses-01_space-T1w_brainmask.nii.gz</span></code></pre>
</div>
<figure><img src="../fig/preprocessing/T1w_brainmask.png" alt="T1w brainmask" class="figure mx-auto d-block"></figure><p>Note, we use <code>bet</code> here, as well as the second inversion
of the anatomical image, as it provides us with a better brainmask. The
<code>bet</code> command above is called to output only the binary mask
and the fractional intensity threshold is also increased slightly (to
0.6) provide a smaller outline of the brain initially, and then
decreased (to 0.4) to provide a larger outline. The flag <code>-m</code>
indicates to the tool to create a brainmask in addition to outputting
the extracted brain volume. Both the mask and brain volume will be used
in our registration step.</p>
<p>Before we get to the registration, we will also update our DWI
brainmask by performing a brain extraction using <code>DIPY</code> on
the eddy corrected image. Note that the output of <code>eddy</code> is
not in BIDS format so we will include the path to the diffusion data
manually. We will save both the brainmask and the extracted brain
volume. Additionally, we will save a separate volume of only the first
B0 to use for the registration.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="im">from</span> dipy.segment.mask <span class="im">import</span> median_otsu</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="co"># Path of FSL eddy-corrected dwi</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>dwi <span class="op">=</span> <span class="st">"../../data/ds000221/derivatives/uncorrected_topup_eddy/sub-010006/ses-01/dwi/dwi.nii.gz"</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="co"># Load eddy-corrected diffusion data</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>dwi <span class="op">=</span> nib.load(dwi)</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>dwi_affine <span class="op">=</span> dwi.affine</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>dwi_data <span class="op">=</span> dwi.get_fdata()</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>dwi_brain, dwi_mask <span class="op">=</span> median_otsu(dwi_data, vol_idx<span class="op">=</span>[<span class="dv">0</span>])</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>dwi_b0 <span class="op">=</span> dwi_brain[:,:,:,<span class="dv">0</span>]</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a><span class="co"># Output directory</span></span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>out_dir<span class="op">=</span><span class="st">"../../data/ds000221/derivatives/uncorrected_topup_eddy/sub-010006/ses-01/dwi"</span></span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a><span class="co"># Save diffusion mask</span></span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a>img <span class="op">=</span> nib.Nifti1Image(dwi_mask.astype(np.float32), dwi_affine)</span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>nib.save(img, os.path.join(out_dir, <span class="st">"sub-010006_ses-01_dwi_proc-eddy_brainmask.nii.gz"</span>))</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a><span class="co"># Save 4D diffusion volume</span></span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a>img <span class="op">=</span> nib.Nifti1Image(dwi_brain, dwi_affine)</span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>nib.save(img, os.path.join(out_dir, <span class="st">"sub-010006_ses-01_dwi_proc-eddy_brain.nii.gz"</span>))</span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a><span class="co"># Save b0 volume</span></span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>img <span class="op">=</span> nib.Nifti1Image(dwi_b0, dwi_affine)</span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a>nib.save(img, os.path.join(out_dir, <span class="st">"sub-010006_ses-01_dwi_proc-eddy_b0.nii.gz"</span>))</span></code></pre>
</div>
<p>To perform the registration between the diffusion volumes and T1w, we
will make use of <code>ANTs</code>, specifically the
<code>antsRegistrationSyNQuick.sh</code> script and
<code>antsApplyTransform</code>. We will begin by registering the
diffusion <span class="math inline">\(b = 0 s/mm^2\)</span> volume to
get the appropriate transforms to align the two images. We will then
apply the inverse transformation to the T1w volume such that it is
aligned to the diffusion volume.</p>
<p>Here, we will constrain <code>antsRegistrationSyNQuick.sh</code> to
perform a rigid and affine transformation (we will explain why in the
final step). There are a few parameters that must be set:</p>
<ul>
<li>
<code>-d</code> - Image dimension (2/3D).</li>
<li>
<code>-t</code> - Transformation type (<code>a</code> performs only
rigid + affine transformation).</li>
<li>
<code>-f</code> - Fixed image (anatomical T1w).</li>
<li>
<code>-m</code> - Moving image (B0 DWI volume).</li>
<li>
<code>-o</code> - Output prefix (prefix to be appended to output
files).</li>
</ul>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="fu">mkdir</span> <span class="at">-p</span> ../../data/ds000221/derivatives/uncorrected_topup_eddy_regT1/sub-010006/ses-01/transforms</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="co"># Perform registration between b0 and T1w</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a><span class="ex">antsRegistrationSyNQuick.sh</span> <span class="at">-d</span> 3 <span class="at">-t</span> a <span class="at">-f</span> ../../data/ds000221/derivatives/uncorrected/sub-010006/ses-01/anat/sub-010006_ses-01_space-T1w_brain.nii.gz <span class="at">-m</span> ../../data/ds000221/derivatives/uncorrected_topup_eddy/sub-010006/ses-01/dwi/sub-010006_ses-01_dwi_proc-eddy_b0.nii.gz <span class="at">-o</span> ../../data/ds000221/derivatives/uncorrected_topup_eddy_regT1/sub-010006/ses-01/transform/dwi_to_t1_</span></code></pre>
</div>
<p>The transformation file should be created which we will use to apply
the inverse transform with <code>antsApplyTransform</code> to the T1w
volume. Similar to the previous command, there are few parameters that
will need to be set:</p>
<ul>
<li>
<code>-d</code> - Image dimension (2/3/4D).</li>
<li>
<code>-i</code> - Input volume to be transformed (T1w).</li>
<li>
<code>-r</code> - Reference volume (B0 DWI volume).</li>
<li>
<code>-t</code> - Transformation file (can be called more than
once).</li>
<li>
<code>-o</code> - Output volume in the transformed space.</li>
</ul>
<p>Note that if more than 1 transformation file is provided, the order
in which the transforms are applied to the volume is in reverse order of
how it is inputted (e.g. last transform gets applied first).</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># Apply transform to 4D DWI volume</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="ex">antsApplyTransforms</span> <span class="at">-d</span> 3 <span class="at">-i</span> ../../data/ds000221/derivatives/uncorrected/sub-010006/ses-01/anat/sub-010006_ses-01_space-T1w_brain.nii.gz <span class="at">-r</span> ../../data/ds000221/derivatives/uncorrected_topup_eddy/sub-010006/ses-01/dwi/sub-010006_ses-01_dwi_proc-eddy_b0.nii.gz <span class="at">-t</span> <span class="pp">[</span><span class="ss">../../data/ds000221/derivatives/uncorrected_topup_eddy_regT1/sub</span><span class="pp">-</span><span class="ss">010006/ses</span><span class="pp">-</span><span class="ss">01/transform/dwi_to_t1_0GenericAffine.mat,1</span><span class="pp">]</span> <span class="at">-o</span> ../../data/ds000221/derivatives/uncorrected_topup_eddy_regT1/sub-010006/ses-01/anat/sub-010006_ses-01_space-dwi_T1w_brain.nii.gz</span></code></pre>
</div>
<figure><img src="../fig/preprocessing/transformed_volumes.png" alt="Transformed volumes" class="figure mx-auto d-block"></figure><p>Following the transformation of the T1w volume, we can see that
anatomical and diffusion weighted volumes are now aligned. It should be
highlighted that as part of the transformation step, the T1w volume is
resampled based on the voxel size of the reference volume (i.e. the B0
DWI volume in this case).</p>
</div>
<div class="section level3">
<h3 id="preprocessing-notes">Preprocessing notes:<a class="anchor" aria-label="anchor" href="#preprocessing-notes"></a>
</h3>
<ol style="list-style-type: decimal">
<li>In this lesson, the T1w volume is registered to the DWI volume. This
method minimizes the manipulation of the diffusion data. It is also
possible to register the DWI volume to the T1w volume and would require
the associated diffusion gradient vectors (bvec) to also be similarly
rotated. If this step is not performed, one would have incorrect
diffusion gradient directions relative to the registered DWI volumes.
This also highlights a reason behind not performing a non-linear
transformation for registration, as each individual diffusion gradient
direction would also have to be subsequently warped. Rotation of the
diffusion gradient vectors can be done by applying the affine
transformation to each row of the file. Luckily, there are existing
scripts that can do this. One such Python script was created by Michael
Paquette: <a href="https://gist.github.com/mpaquette/5d59ad195778f9d984c5def42f53de6e" class="external-link"><code>rot_bvecs_ants.py</code></a>.</li>
<li>We have only demonstrated the preprocessing steps where there is
general consensus on how DWI data should be processed. There are also
additional steps with certain caveats, which include denoising,
unringing (to remove/minimize effects of Gibbs ringing artifacts), and
gradient non-linearity correction (to unwarp distortions caused by
gradient-field inhomogeneities using a vendor acquired gradient
coefficient file).</li>
<li>Depending on how the data is acquired, certain steps may not be
possible. For example, if the data is not acquired in two directions,
<code>topup</code> may not be possible (in this situation, distortion
correction may be better handled by registering with a T1w anatomical
image directly.</li>
<li>There are also a number of tools available for preprocessing. In
this lesson, we demonstrate some of the more commonly used tools
alongside <code>DIPY</code>.</li>
</ol>
</div>
<div class="section level3">
<h3 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h3>
<p>.. [Cieslak2020] M. Cieslak, PA. Cook, X. He, F-C. Yeh, T.
Dhollander, <em>et al</em>, “QSIPrep: An integrative platform for
preprocessing and reconstructing diffusion MRI”, <a href="https://doi.org/10.1101/2020.09.04.282269" class="external-link">https://doi.org/10.1101/2020.09.04.282269</a></p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Many different preprocessing pipelines, dependent on how data is
acquired</li>
</ul>
</div>
</div>
</div>
<!-- Workshop-specific links -->
</div>
</section></section><section id="aio-local_orientation_reconstruction"><p>Content from <a href="local_orientation_reconstruction.html">Local fiber orientation reconstruction</a></p>
<hr>
<p>Last updated on 2024-02-18 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-dMRI/edit/main/episodes/local_orientation_reconstruction.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 140 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What information can dMRI provide at the voxel level?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Present different local orientation reconstruction methods</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="orientation-reconstruction">Orientation reconstruction<a class="anchor" aria-label="anchor" href="#orientation-reconstruction"></a>
</h2>
<hr class="half-width">
<p>Diffusion MRI is sensitive to the underlying white matter fiber
orientation distribution. Once the data has been pre-processed to remove
noise and other acquisition artefacts, dMRI data can be used to extract
features that describe the white matter. Estimating or reconstructing
the local fiber orientation is the first step to gain such insight.</p>
<p>The local fiber orientation reconstruction task faces several
challenges derived, among others, by the orientational heterogeneity
that the white matter presents at the voxel level. Due to the
arrangement of the white matter fibers, and the scale and limits of the
diffusion modality itself, a large amount of voxels are traversed by
several fibers. Resolving such configurations with incomplete
information is not a solved task. Several additional factors, such as
imperfect models or their choices, influence the reconstruction results,
and hence the downstream results.</p>
<p>The following is a (non-exhaustive) list of the known local
orientation reconstruction methods:</p>
<ul>
<li>Diffusion Tensor Imaging (DTI) (Basser et al., 1994)</li>
<li>Q-ball Imaging (QBI) (Tuch 2004; Descoteaux et al. 2007)</li>
<li>Diffusion Kurtosis Imaging (DKI) (Jensen et al. 2005)</li>
<li>Constrained Spherical Deconvolution (CSD) (Tournier et
al. 2007)</li>
<li>Diffusion Spectrum Imaging (DSI) (Wedeen et al. 2008)</li>
<li>Simple Harmonic Oscillator based Reconstruction and Estimation
(SHORE) (Özarslan et al. 2008)</li>
<li>Constant Solid Angle (CSA) (Aganj et al. 2009)</li>
<li>Damped Richardson-Lucy Spherical Deconvolution (dRL-SD) (Dell’Acqua
et al. 2010)</li>
<li>DSI with deconvolution (Canales-Rodriguez et al. 2010)</li>
<li>Generalized Q-sampling Imaging (Yeh et al. 2010)</li>
<li>Orientation Probability Density Transform (OPDT) (Tristan-Vega et
al. 2010)</li>
<li>Mean Apparent Propagator (MAPMRI) (Özarslan et al. 2013)</li>
<li>Sparse Fascicle Model (SFM) (Rokem et al. 2015)</li>
<li>Robust and Unbiased Model-Based Spherical Deconvolution (RUMBA-SD)
(Canales-Rodriguez et al. 2015)</li>
<li>Sparse Bayesian Learning (SBL) (Canales-Rodriguez et al. 2019)</li>
</ul>
<p>These methods vary in terms of the required data. Hence, there are a
few factors that influence the choice for a given reconstruction
method:</p>
<ul>
<li>The available data in terms of the number of (b-value) shells
(single- or multi-shell).</li>
<li>The acquisition/sampling scheme.</li>
<li>The available time to reconstruct the data.</li>
</ul>
<p>Besides such requirements, the preference over a method generally
lies in its ability to resolve complex fiber configurations, such as
fiber crossings at reduced angles. Additionally, some of these methods
provide additional products beyond the orientation reconstruction that
might also be of interest.</p>
<p>Finally, several deep learning-based methods have been proposed to
estimate the local fiber orientation using the diffusion MRI data.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Provides an estimation of the local (voxel-wise) underlying fiber
orientation</li>
<li>Local fiber orientation reconstruction is the primer to all dMRI
derivatives</li>
</ul>
</div>
</div>
</div>
<!-- Workshop-specific links -->
</section></section><section id="aio-diffusion_tensor_imaging"><p>Content from <a href="diffusion_tensor_imaging.html">Diffusion Tensor Imaging (DTI)</a></p>
<hr>
<p>Last updated on 2024-02-18 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-dMRI/edit/main/episodes/diffusion_tensor_imaging.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 35 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is diffusion tensor imaging?</li>
<li>What metrics can be derived from DTI?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the tensor model and derived metrics</li>
<li>Visualizing tensors</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="diffusion-tensor-imaging-dti">Diffusion Tensor Imaging (DTI)<a class="anchor" aria-label="anchor" href="#diffusion-tensor-imaging-dti"></a>
</h2>
<hr class="half-width">
<p>Diffusion tensor imaging or “DTI” refers to images describing
diffusion with a tensor model. DTI is derived from preprocessed
diffusion weighted imaging (DWI) data. First proposed by Basser and
colleagues (<a href="https://www.ncbi.nlm.nih.gov/pubmed/8130344" class="external-link">Basser, 1994</a>),
the diffusion tensor model describes diffusion characteristics within an
imaging voxel. This model has been very influential in demonstrating the
utility of the diffusion MRI in characterizing the microstructure of
white matter and the biophysical properties (inferred from local
diffusion properties). The DTI model is still a commonly used model to
investigate white matter.</p>
<p>The tensor models the diffusion signal mathematically as:</p>
<figure><img src="../fig/diffusion_tensor_imaging/diffusion_eqn.png" alt="Diffusion signal equation" class="figure mx-auto d-block"></figure><p>Where <span class="math inline">\(\boldsymbol{g}\)</span> is a unit
vector in 3D space indicating the direction of measurement and <span class="math inline">\(b\)</span> are the parameters of the measurement,
such as the strength and duration of diffusion-weighting gradient. <span class="math inline">\(S(\boldsymbol{g}, b)\)</span> is the
diffusion-weighted signal measured and <span class="math inline">\(S_{0}\)</span> is the signal conducted in a
measurement with no diffusion weighting. <span class="math inline">\(\boldsymbol{D}\)</span> is a positive-definite
quadratic form, which contains six free parameters to be fit. These six
parameters are:</p>
<figure><img src="../fig/diffusion_tensor_imaging/diffusion_matrix.png" alt="Diffusivity matrix" class="figure mx-auto d-block"></figure><p>The diffusion matrix is a variance-covariance matrix of the
diffusivity along the three spatial dimensions. Note that we can assume
that the diffusivity has antipodal symmetry, so elements across the
diagonal of the matrix are equal. For example: <span class="math inline">\(D_{xy} = D_{yx}\)</span>. This is why there are
only 6 free parameters to estimate here.</p>
<p>Tensors are represented by ellipsoids characterized by calculated
eigenvalues (<span class="math inline">\(\lambda_{1}, \lambda_{2},
\lambda_{3}\)</span>) and (<span class="math inline">\(\epsilon_{1},
\epsilon_{2}, \epsilon_{3}\)</span>) eigenvectors from the previously
described matrix. The computed eigenvalues and eigenvectors are normally
sorted in descending magnitude (i.e. <span class="math inline">\(\lambda_{1} \geq \lambda_{2}\)</span>).
Eigenvalues are always strictly positive in the context of dMRI and are
measured in <span class="math inline">\(mm^2/s\)</span>. In the DTI
model, the largest eigenvalue gives the principal direction of the
diffusion tensor, and the other two eigenvectors span the orthogonal
plane to the former direction.</p>
<p><img src="../fig/diffusion_tensor_imaging/DiffusionTensor.png" alt="Diffusion tensor" class="figure"><em>Adapted from Jelison et al., 2004</em></p>
<p>In the following example, we will walk through how to model a
diffusion dataset. While there are a number of diffusion models, many of
which are implemented in <code>DIPY</code>. However, for the purposes of
this lesson, we will focus on the tensor model described above.</p>
<div class="section level3">
<h3 id="reconstruction-with-the-dipy-reconst-module">Reconstruction with the <code>dipy.reconst</code> module<a class="anchor" aria-label="anchor" href="#reconstruction-with-the-dipy-reconst-module"></a>
</h3>
<p>The <code>reconst</code> module contains implementations of the
following models:</p>
<ul>
<li>Tensor (Basser et al., 1994)</li>
<li>Constrained Spherical Deconvolution (Tournier et al. 2007)</li>
<li>Diffusion Kurtosis (Jensen et al. 2005)</li>
<li>DSI (Wedeen et al. 2008)</li>
<li>DSI with deconvolution (Canales-Rodriguez et al. 2010)</li>
<li>Generalized Q Imaging (Yeh et al. 2010)</li>
<li>MAPMRI (Özarslan et al. 2013)</li>
<li>SHORE (Özarslan et al. 2008)</li>
<li>CSA (Aganj et al. 2009)</li>
<li>Q ball (Descoteaux et al. 2007)</li>
<li>OPDT (Tristan-Vega et al. 2010)</li>
<li>Sparse Fascicle Model (Rokem et al. 2015)</li>
</ul>
<p>The different algorithms implemented in the module all share a
similar conceptual structure:</p>
<ul>
<li>
<code>ReconstModel</code> objects (e.g. <code>TensorModel</code>)
carry the parameters that are required in order to fit a model. For
example, the directions and magnitudes of the gradients that were
applied in the experiment. <code>TensorModel</code> objects have a
<code>fit</code> method, which takes in data, and returns a
<code>ReconstFit</code> object. This is where a lot of the heavy lifting
of the processing will take place.</li>
<li>
<code>ReconstFit</code> objects carry the model that was used to
generate the object. They also include the parameters that were
estimated during fitting of the data. They have methods to calculate
derived statistics, which can differ from model to model. All objects
also have an orientation distribution function (<code>odf</code>), and
most (but not all) contain a <code>predict</code> method, which enables
the prediction of another dataset based on the current gradient
table.</li>
</ul>
</div>
<div class="section level3">
<h3 id="reconstruction-with-the-dti-model">Reconstruction with the DTI Model<a class="anchor" aria-label="anchor" href="#reconstruction-with-the-dti-model"></a>
</h3>
<p>Let’s get started! First, we will need to grab the
<strong>preprocessed</strong> DWI files and load them! We will also load
in the anatomical image to use as a reference later on.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> bids.layout <span class="im">import</span> BIDSLayout</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> dipy.io.gradients <span class="im">import</span> read_bvals_bvecs</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> dipy.core.gradients <span class="im">import</span> gradient_table</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> image <span class="im">as</span> img</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>deriv_layout <span class="op">=</span> BIDSLayout(<span class="st">"../data/ds000221/derivatives"</span>, validate<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>subj<span class="op">=</span><span class="st">"010006"</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="co"># Grab the transformed t1 file for reference</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>t1 <span class="op">=</span> deriv_layout.get(subject<span class="op">=</span>subj, space<span class="op">=</span><span class="st">"dwi"</span>, extension<span class="op">=</span><span class="st">'.nii.gz'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="co"># Recall the preprocessed data is no longer in BIDS - we will directly grab these files</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>dwi <span class="op">=</span> <span class="ss">f"../data/ds000221/derivatives/uncorrected_topup_eddy/sub-</span><span class="sc">{</span>subj<span class="sc">}</span><span class="ss">/ses-01/dwi/dwi.nii.gz"</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>bval <span class="op">=</span> <span class="ss">f"../data/ds000221/sub-</span><span class="sc">{</span>subj<span class="sc">}</span><span class="ss">/ses-01/dwi/sub-</span><span class="sc">{</span>subj<span class="sc">}</span><span class="ss">_ses-01_dwi.bval"</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>bvec <span class="op">=</span> <span class="ss">f"../data/ds000221/derivatives/uncorrected_topup_eddy/sub-</span><span class="sc">{</span>subj<span class="sc">}</span><span class="ss">/ses-01/dwi/dwi.eddy_rotated_bvecs"</span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>t1_data <span class="op">=</span> img.load_img(t1)</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>dwi_data <span class="op">=</span> img.load_img(dwi)</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>gt_bvals, gt_bvecs <span class="op">=</span> read_bvals_bvecs(bval, bvec)</span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>gtab <span class="op">=</span> gradient_table(gt_bvals, gt_bvecs)</span></code></pre>
</div>
<p>Next, we will need to create the tensor model using our gradient
table, and then fit the model using our data! We start by creating a
mask from our data. We then apply this mask to avoid calculating the
tensors in the background of the image! This can be done using
<code>DIPY</code>’s mask module. Then we will fit out data!</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">import</span> dipy.reconst.dti <span class="im">as</span> dti</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">from</span> dipy.segment.mask <span class="im">import</span> median_otsu</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>dwi_data <span class="op">=</span> dwi_data.get_fdata()</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>dwi_data, dwi_mask <span class="op">=</span> median_otsu(dwi_data, vol_idx<span class="op">=</span>[<span class="dv">0</span>], numpass<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>dti_model <span class="op">=</span> dti.TensorModel(gtab)</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>dti_fit <span class="op">=</span> dti_model.fit(dwi_data, mask<span class="op">=</span>dwi_mask)</span></code></pre>
</div>
<p>The fit method creates a <code>TensorFit</code> object which contains
the fitting parameters and other attributes of the model. A number of
quantitative scalar metrics can be derived from the eigenvalues! In this
tutorial, we will cover fractional anisotropy, mean diffusivity, axial
diffusivity, and radial diffusivity. Each of these scalar, rotationally
invariant metrics were calculated in the previous fitting step!</p>
</div>
<div class="section level3">
<h3 id="fractional-anisotropy-fa">Fractional anisotropy (FA)<a class="anchor" aria-label="anchor" href="#fractional-anisotropy-fa"></a>
</h3>
<p>Fractional anisotropy (FA) characterizes the degree to which the
distribution of diffusion in an imaging voxel is directional. That is,
whether there is relatively unrestricted diffusion in a particular
direction.</p>
<p>Mathematically, FA is defined as the normalized variance of the
eigenvalues of the tensor:</p>
<figure><img src="../fig/diffusion_tensor_imaging/fa_eqn.png" alt="FA equation" class="figure mx-auto d-block"></figure><p>Values of FA vary between 0 and 1 (unitless). In the cases of
perfect, isotropic diffusion, <span class="math inline">\(\lambda_{1} =
\lambda_{2} = \lambda_{3}\)</span>, the diffusion tensor is a sphere and
FA = 0. If the first two eigenvalues are equal the tensor will be oblate
or planar, whereas if the first eigenvalue is larger than the other two,
it will have the mentioned ellipsoid shape: as diffusion progressively
becomes more anisotropic, eigenvalues become more unequal, causing the
tensor to be elongated, with FA approaching 1. Note that FA should be
interpreted carefully. It may be an indication of the density of packing
fibers in a voxel and the amount of myelin wrapped around those axons,
but it is not always a measure of “tissue integrity”.</p>
<p>Let’s take a look at what the FA map looks like! An FA map is a
gray-scale image, where higher intensities reflect more anisotropic
diffuse regions.</p>
<p>We will create the FA image from the scalar data array using the
anatomical reference image data as the reference image:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt <span class="co"># To enable plotting within notebook</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> plotting <span class="im">as</span> plot</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>fa_img <span class="op">=</span> img.new_img_like(ref_niimg<span class="op">=</span>t1_data, data<span class="op">=</span>dti_fit.fa)</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>plot.plot_anat(fa_img)</span></code></pre>
</div>
<figure><img src="../fig/diffusion_tensor_imaging/plot_fa.png" alt="FA plot" class="figure mx-auto d-block"></figure><p>Derived from partial volume effects in imaging voxels due to the
presence of different tissues, noise in the measurements and numerical
errors, the DTI model estimation may yield negative eigenvalues. Such
<em>degenerate</em> case is not physically meaningful. These values are
usually revealed as black or 0-valued pixels in FA maps.</p>
<p>FA is a central value in dMRI: large FA values imply that the
underlying fiber populations have a very coherent orientation, whereas
lower FA values point to voxels containing multiple fiber crossings.
Lowest FA values are indicative of non-white matter tissue in healthy
brains (see, for example, Alexander et al.’s “Diffusion Tensor Imaging
of the Brain”. Neurotherapeutics 4, 316-329 (2007), and Jeurissen et
al.’s “Investigating the Prevalence of Complex Fiber Configurations in
White Matter Tissue with Diffusion Magnetic Resonance Imaging”. Hum.
Brain Mapp. 2012, 34(11) pp. 2747-2766).</p>
</div>
<div class="section level3">
<h3 id="mean-diffusivity-md">Mean diffusivity (MD)<a class="anchor" aria-label="anchor" href="#mean-diffusivity-md"></a>
</h3>
<p>An often used complimentary measure to FA is mean diffusivity (MD).
MD is a measure of the degree of diffusion, independent of direction.
This is sometimes known as the apparent diffusion coefficient (ADC).
Mathematically, MD is computed as the mean eigenvalues of the tensor and
is measured in <span class="math inline">\(mm^2/s\)</span>.</p>
<figure><img src="../fig/diffusion_tensor_imaging/md_eqn.png" alt="MD equation" class="figure mx-auto d-block"></figure><p>Similar to the previous FA image, let’s take a look at what the MD
map looks like. Again, higher intensities reflect higher mean
diffusivity!</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>md_img <span class="op">=</span> img.new_img_like(ref_niimg<span class="op">=</span>t1_data, data<span class="op">=</span>dti_fit.md)</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="co"># Arbitrarily set min and max of color bar</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>plot.plot_anat(md_img, cut_coords<span class="op">=</span>(<span class="dv">0</span>, <span class="op">-</span><span class="dv">29</span>, <span class="dv">20</span>), vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="fl">0.01</span>)</span></code></pre>
</div>
<figure><img src="../fig/diffusion_tensor_imaging/plot_md.png" alt="MD plot" class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="axial-and-radial-diffusivity-ad-rd">Axial and radial diffusivity (AD &amp; RD)<a class="anchor" aria-label="anchor" href="#axial-and-radial-diffusivity-ad-rd"></a>
</h3>
<p>The final two metrics we will discuss are axial diffusivity (AD) and
radial diffusivity (RD). Two tensors with different shapes may yield the
same FA values, and additional measures such as AD and RD are required
to further characterize the tensor. AD describes the diffusion rate
along the primary axis of diffusion, along <span class="math inline">\(\lambda_{1}\)</span>, or parallel to the axon (and
hence, some works refer to it as the <em>parallel diffusivity</em>). On
the other hand, RD reflects the average diffusivity along the other two
minor axes (being named as <em>perpendicular diffusivity</em> in some
works) (<span class="math inline">\(\lambda_{2}, \lambda_{3}\)</span>).
Both are measured in <span class="math inline">\(mm^2/s\)</span>.</p>
<figure><img src="../fig/diffusion_tensor_imaging/ax_rad_diff.png" alt="Axial and radial diffusivities" class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="tensor-visualizations">Tensor visualizations<a class="anchor" aria-label="anchor" href="#tensor-visualizations"></a>
</h3>
<p>There are several ways of visualizing tensors. One way is using an
RGB map, which overlays the primary diffusion orientation on an FA map.
The colours of this map encodes the diffusion orientation. Note that
this map provides no directional information (e.g. whether the diffusion
flows from right-to-left or vice-versa). To do this with
<code>DIPY</code>, we can use the <code>color_fa</code> function. The
colours map to the following orientations:</p>
<ul>
<li>Red = Left / Right</li>
<li>Green = Anterior / Posterior</li>
<li>Blue = Superior / Inferior</li>
</ul>
<div id="diffusion-scalar-map-visualization" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="diffusion-scalar-map-visualization" class="callout-inner">
<h3 class="callout-title">Diffusion scalar map visualization</h3>
<div class="callout-content">
<p>The plotting functions in <a href="https://nilearn.github.io/stable/index.html" class="external-link">Nilearn</a> are
unable to visualize these RGB maps. However, we can use the <a href="https://matplotlib.org/" class="external-link">Matplotlib</a> library to view these
images.</p>
</div>
</div>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">from</span> dipy.reconst.dti <span class="im">import</span> color_fa</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>RGB_map <span class="op">=</span> color_fa(dti_fit.fa, dti_fit.evecs)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> ndimage</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>ax[<span class="dv">0</span>].imshow(ndimage.rotate(RGB_map[:, RGB_map.shape[<span class="dv">1</span>]<span class="op">//</span><span class="dv">2</span>, :, :], <span class="dv">90</span>, reshape<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>ax[<span class="dv">1</span>].imshow(ndimage.rotate(RGB_map[RGB_map.shape[<span class="dv">0</span>]<span class="op">//</span><span class="dv">2</span>, :, :, :], <span class="dv">90</span>, reshape<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>ax[<span class="dv">2</span>].imshow(ndimage.rotate(RGB_map[:, :, RGB_map.shape[<span class="dv">2</span>]<span class="op">//</span><span class="dv">2</span>, :], <span class="dv">90</span>, reshape<span class="op">=</span><span class="va">False</span>))</span></code></pre>
</div>
<figure><img src="../fig/diffusion_tensor_imaging/plot_fa_rgb.png" alt="RGB FA map" class="figure mx-auto d-block"></figure><p>Another way of visualizing the tensors is to display the diffusion
tensor in each imaging voxel with colour encoding. Below is an example
of one such tensor visualization.</p>
<figure><img src="../fig/diffusion_tensor_imaging/TensorViz.png" alt="Tensor visualization" class="figure mx-auto d-block"></figure><div id="tensor-visualization" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="tensor-visualization" class="callout-inner">
<h3 class="callout-title">Tensor visualization</h3>
<div class="callout-content">
<p>Visualizing tensors can be memory intensive. Please refer to the <a href="https://dipy.org/tutorials/" class="external-link">DIPY documentation</a> for the
necessary steps to perform this type of visualization.</p>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="some-notes-on-dti">Some notes on DTI<a class="anchor" aria-label="anchor" href="#some-notes-on-dti"></a>
</h3>
<p>DTI is only one of many models and is one of the simplest models
available for modelling diffusion. While it is used for many studies,
there are also some drawbacks (e.g. ability to distinguish multiple
fibre orientations in an imaging voxel). Examples of this can be seen
below!</p>
<figure><img src="../fig/diffusion_tensor_imaging/FiberConfigurations.png" alt="DTI drawbacks" class="figure mx-auto d-block"></figure><p><em>Sourced from Sotiropoulos and Zalesky (2017). Building
connectomes using diffusion MRI: why, how, and but. NMR in Biomedicine.
4(32). e3752. <a href="../doi:10.1002/nbm.3752" class="uri">doi:10.1002/nbm.3752</a>.</em></p>
<p>Though other models are outside the scope of this lesson, we
recommend looking into some of the pros and cons of each model (listed
previously) to choose one best suited for your data!</p>
<div id="exercise-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise-1" class="callout-inner">
<h3 class="callout-title">Exercise 1</h3>
<div class="callout-content">
<p>Plot the axial and radial diffusivity maps of the example given.
Start from fitting the preprocessed diffusion image.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="im">from</span> bids.layout <span class="im">import</span> BIDSLayout</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="im">from</span> dipy.io.gradients <span class="im">import</span> read_bvals_bvecs</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="im">from</span> dipy.core.gradients <span class="im">import</span> gradient_table</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="im">import</span> dipy.reconst.dti <span class="im">as</span> dti</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="im">from</span> dipy.segment.mask <span class="im">import</span> median_otsu</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> image <span class="im">as</span> img</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>deriv_layout <span class="op">=</span> BIDSLayout(<span class="st">"../data/ds000221/derivatives"</span>, validate<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>subj<span class="op">=</span><span class="st">"010006"</span></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>t1 <span class="op">=</span> deriv_layout.get(subject<span class="op">=</span>subj, space<span class="op">=</span><span class="st">"dwi"</span>, extension<span class="op">=</span><span class="st">'.nii.gz'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>dwi <span class="op">=</span> <span class="ss">f"../data/ds000221/derivatives/uncorrected_topup_eddy/sub-</span><span class="sc">{</span>subj<span class="sc">}</span><span class="ss">/ses-01/dwi/dwi.nii.gz"</span></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>bval <span class="op">=</span> <span class="ss">f"../data/ds000221/sub-</span><span class="sc">{</span>subj<span class="sc">}</span><span class="ss">/ses-01/dwi/sub-</span><span class="sc">{</span>subj<span class="sc">}</span><span class="ss">_ses-01_dwi.bval"</span></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a>bvec <span class="op">=</span> <span class="ss">f"../data/ds000221/derivatives/uncorrected_topup_eddy/sub-</span><span class="sc">{</span>subj<span class="sc">}</span><span class="ss">/ses-01/dwi/dwi.eddy_rotated_bvecs"</span></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>t1_data <span class="op">=</span> img.load_img(t1)</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a>dwi_data <span class="op">=</span> img.load_img(dwi)</span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a>gt_bvals, gt_bvecs <span class="op">=</span> read_bvals_bvecs(bval, bvec)</span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a>gtab <span class="op">=</span> gradient_table(gt_bvals, gt_bvecs)</span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a>dwi_data <span class="op">=</span> dwi_data.get_fdata()</span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a>dwi_data, dwi_mask <span class="op">=</span> median_otsu(dwi_data, vol_idx<span class="op">=</span>[<span class="dv">0</span>], numpass<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a><span class="co"># Fit dti model</span></span>
<span id="cb6-26"><a href="#cb6-26" tabindex="-1"></a>dti_model <span class="op">=</span> dti.TensorModel(gtab)</span>
<span id="cb6-27"><a href="#cb6-27" tabindex="-1"></a>dti_fit <span class="op">=</span> dti_model.fit(dwi_data, mask<span class="op">=</span>dwi_mask) <span class="co"># This step may take a while</span></span>
<span id="cb6-28"><a href="#cb6-28" tabindex="-1"></a></span>
<span id="cb6-29"><a href="#cb6-29" tabindex="-1"></a><span class="co"># Plot axial diffusivity map</span></span>
<span id="cb6-30"><a href="#cb6-30" tabindex="-1"></a>ad_img <span class="op">=</span> img.new_img_like(ref_niimg<span class="op">=</span>t1_data, data<span class="op">=</span>dti_fit.ad)</span>
<span id="cb6-31"><a href="#cb6-31" tabindex="-1"></a>plot.plot_anat(ad_img, cut_coords<span class="op">=</span>(<span class="dv">0</span>, <span class="op">-</span><span class="dv">29</span>, <span class="dv">20</span>), vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb6-32"><a href="#cb6-32" tabindex="-1"></a></span>
<span id="cb6-33"><a href="#cb6-33" tabindex="-1"></a><span class="co"># Plot radial diffusivity map</span></span>
<span id="cb6-34"><a href="#cb6-34" tabindex="-1"></a>rd_img <span class="op">=</span> img.new_img_like(ref_niimg<span class="op">=</span>t1_data, data<span class="op">=</span>dti_fit.rd)</span>
<span id="cb6-35"><a href="#cb6-35" tabindex="-1"></a>plot.plot_anat(rd_img, cut_coords<span class="op">=</span>(<span class="dv">0</span>, <span class="op">-</span><span class="dv">29</span>, <span class="dv">20</span>), vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="fl">0.01</span>)</span></code></pre>
</div>
<p><img src="../fig/diffusion_tensor_imaging/axial_diffusivity_map.png" alt="Axial diffusivity map" class="figure"><br>
Axial diffusivity map.</p>
<p><img src="../fig/diffusion_tensor_imaging/radial_diffusivity_map.png" alt="Radial diffusivity map" class="figure"><br>
Radial diffusivity map.</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>DTI is one of the simplest and most common models used</li>
<li>Provides information to infer characteristics of axonal fibres</li>
</ul>
</div>
</div>
</div>
<!-- Workshop-specific links -->
</div>
</section></section><section id="aio-constrained_spherical_deconvolution"><p>Content from <a href="constrained_spherical_deconvolution.html">Constrained Spherical Deconvolution (CSD)</a></p>
<hr>
<p>Last updated on 2024-02-18 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-dMRI/edit/main/episodes/constrained_spherical_deconvolution.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 35 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is Constrained Spherical Deconvolution (CSD)?</li>
<li>What does CSD offer compared to DTI?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand Spherical Deconvolution</li>
<li>Visualizing the fiber Orientation Distribution Function</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="constrained-spherical-deconvolution-csd">Constrained Spherical Deconvolution (CSD)<a class="anchor" aria-label="anchor" href="#constrained-spherical-deconvolution-csd"></a>
</h2>
<hr class="half-width">
<p>Spherical Deconvolution (SD) is a set of methods to reconstruct the
local fiber Orientation Distribution Functions (fODF) from diffusion MRI
data. They have become a popular choice for recovering the fiber
orientation due to their ability to resolve fiber crossings with small
inter-fiber angles in datasets acquired within a clinically feasible
scan time. SD methods are based on the assumption that the acquired
diffusion signal in each voxel can be modeled as a spherical convolution
between the fODF and the fiber response function (FRF) that describes
the common signal profile from the white matter (WM) bundles contained
in the voxel. Thus, if the FRF can be estimated, the fODF can be
recovered as a deconvolution problem by solving a system of linear
equations. These methods can work on both single-shell and multi-shell
data.</p>
<p>The basic equations of an SD method can be summarized as <img src="../fig/constrained_spherical_deconvolution/spherical_deconvolution_equation.png" alt="Spherical deconvolution equation" class="figure"><br>
Spherical deconvolution</p>
<p>There are a number of variants to the general SD framework that
differ, among others, in the minimization objective and the
regularization penalty imposed to obtain some desirable properties in
the linear equation framework.</p>
<p>In order to perform the deconvolution over the sphere, the spherical
representation of the diffusion data has to be obtained. This is done
using the so-called Spherical Harmonics (SH) which are a basis that
allow to represent any function on the sphere (much like the Fourier
analysis allows to represent a function in terms of trigonometric
functions).</p>
<p>In this episode we will be using the Constrained Spherical
Deconvolution (CSD) method proposed by Tournier <em>et al</em>. in 2007.
In essence, CSD imposes a non-negativity constraint in the reconstructed
fODF. For the sake of simplicity, single-shell data will be used in this
episode.</p>
<p>Let’s start by loading the necessary data. For simplicity, we will
assume that the gradient table is the same across all voxels after the
pre-processing.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> nibabel <span class="im">as</span> nib</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">from</span> bids.layout <span class="im">import</span> BIDSLayout</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">from</span> dipy.core.gradients <span class="im">import</span> gradient_table</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="im">from</span> dipy.data <span class="im">import</span> default_sphere</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="im">from</span> dipy.io.gradients <span class="im">import</span> read_bvals_bvecs</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="im">from</span> dipy.io.image <span class="im">import</span> load_nifti</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>dwi_layout <span class="op">=</span> BIDSLayout(<span class="st">'../../data/ds000221/derivatives/uncorrected_topup_eddy/'</span>, validate<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>t1_layout <span class="op">=</span> BIDSLayout(<span class="st">'../../data/ds000221/derivatives/uncorrected_topup_eddy_regT1/'</span>, validate<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>gradient_layout <span class="op">=</span> BIDSLayout(<span class="st">'../../data/ds000221/sub-010006/ses-01/dwi/'</span>, validate<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>subj <span class="op">=</span> <span class="st">'010006'</span></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a><span class="co"># Get the diffusion files</span></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>dwi_fname <span class="op">=</span> dwi_layout.get(subject<span class="op">=</span>subj, suffix<span class="op">=</span><span class="st">'dwi'</span>, extension<span class="op">=</span><span class="st">'.nii.gz'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>bvec_fname <span class="op">=</span> dwi_layout.get(subject<span class="op">=</span>subj, extension<span class="op">=</span><span class="st">'.eddy_rotated_bvecs'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a>bval_fname <span class="op">=</span> gradient_layout.get(subject<span class="op">=</span>subj, suffix<span class="op">=</span><span class="st">'dwi'</span>, extension<span class="op">=</span><span class="st">'.bval'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a><span class="co"># Get the anatomical file</span></span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a>t1w_fname <span class="op">=</span> t1_layout.get(subject<span class="op">=</span>subj, extension<span class="op">=</span><span class="st">'.nii.gz'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb1-27"><a href="#cb1-27" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" tabindex="-1"></a>data, affine <span class="op">=</span> load_nifti(dwi_fname)</span>
<span id="cb1-29"><a href="#cb1-29" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" tabindex="-1"></a>bvals, bvecs <span class="op">=</span> read_bvals_bvecs(bval_fname, bvec_fname)</span>
<span id="cb1-31"><a href="#cb1-31" tabindex="-1"></a>gtab <span class="op">=</span> gradient_table(bvals, bvecs)</span></code></pre>
</div>
<p>You can verify the b-values of the dataset by looking at the
attribute <code>gtab.bvals</code>. Now that a datasets with multiple
gradient directions is loaded, we can proceed with the two steps of
CSD.</p>
</section><section><h2 class="section-heading" id="step-1--estimation-of-the-fiber-response-function-">Step 1. Estimation of the fiber response function.<a class="anchor" aria-label="anchor" href="#step-1--estimation-of-the-fiber-response-function-"></a>
</h2>
<hr class="half-width">
<p>In this episode the response function will be estimated from a local
brain region known to belong to the white matter and where it is known
that there are single coherent fiber populations. This is determined by
checking the Fractional Anisotropy (FA) derived from the DTI model.</p>
<p>For example, if we use an ROI at the center of the brain, we will
find single fibers from the corpus callosum. <code>DIPY</code>’s
<code>auto_response_ssst</code> function will calculate the FA for an
ROI of radius equal to <code>roi_radii</code> in the center of the
volume, and return the response function estimated in that region for
the voxels with FA higher than a given threshold.</p>
<div id="the-fiber-response-function-and-the-diffusion-model" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="the-fiber-response-function-and-the-diffusion-model" class="callout-inner">
<h3 class="callout-title">The fiber response function and the diffusion model</h3>
<div class="callout-content">
<p>The <code>auto_response_ssst</code> method is relevant within a
Single-Shell Single-Tissue (SSST) context/model; e.g. Multi-Shell
Multi-Tissue (MSMT) context/models require the fiber response function
to be computed differently.</p>
</div>
</div>
</div>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> dipy.reconst.csdeconv <span class="im">import</span> auto_response_ssst</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>response, ratio <span class="op">=</span> auto_response_ssst(gtab, data, roi_radii<span class="op">=</span><span class="dv">10</span>, fa_thr<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co"># Create the directory to save the results</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>out_dir <span class="op">=</span> <span class="st">'../../data/ds000221/derivatives/dwi/reconstruction/sub-</span><span class="sc">%s</span><span class="st">/ses-01/dwi/'</span> <span class="op">%</span> subj</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(out_dir):</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>    os.makedirs(out_dir)</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="co"># Save the FRF</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>np.savetxt(os.path.join(out_dir, <span class="st">'frf.txt'</span>), np.hstack([response[<span class="dv">0</span>], response[<span class="dv">1</span>]]))</span></code></pre>
</div>
<p>The <code>response</code> tuple contains two elements. The first is
an array with the eigenvalues of the response function and the second is
the average <code>S0</code> signal value for this response.</p>
<p>Validating the numerical value of the response function is
recommended to ensure that the FA-based strategy provides a good result.
To this end, the elements of the <code>response</code> tuple can be
printed and their values be studied.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="bu">print</span>(response)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(array([0.00160273, 0.00034256, 0.00034256]), 209.55229)</code></pre>
</div>
<p>The tensor generated belonging to the response function must be
prolate (two smaller eigenvalues should be equal), and look anisotropic
with a ratio of second to first eigenvalue of about 0.2. Or in other
words, the axial diffusivity of this tensor should be around 5 times
larger than the radial diffusivity. It is generally accepted that a
response function with the mentioned features is representative of a
coherently oriented fiber population.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="bu">print</span>(ratio)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">0.2137331138364376</span></span></code></pre>
</div>
<p>It is good practice to visualize the response function’s ODF, which
also gives an insightful idea around the SD framework. The response
function’s ODF should have sharp lobes, as the anisotropy of its
diffusivity indicates:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="im">from</span> dipy.sims.voxel <span class="im">import</span> single_tensor_odf</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="im">from</span> fury <span class="im">import</span> window, actor</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>scene <span class="op">=</span> window.Scene()</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>evals <span class="op">=</span> response[<span class="dv">0</span>]</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>evecs <span class="op">=</span> np.array([[<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>]]).T</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>response_odf <span class="op">=</span> single_tensor_odf(default_sphere.vertices, evals, evecs)</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a><span class="co"># transform our data from 1D to 4D</span></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>response_odf <span class="op">=</span> response_odf[<span class="va">None</span>, <span class="va">None</span>, <span class="va">None</span>, :]</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>response_actor <span class="op">=</span> actor.odf_slicer(response_odf, sphere<span class="op">=</span>default_sphere,</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>                                  colormap<span class="op">=</span><span class="st">'plasma'</span>)</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>scene.add(response_actor)</span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>response_scene_arr <span class="op">=</span> window.snapshot(</span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>    scene, fname<span class="op">=</span>os.path.join(out_dir, <span class="st">'frf.png'</span>), size<span class="op">=</span>(<span class="dv">200</span>, <span class="dv">200</span>),</span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>    offscreen<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots()</span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a>axes.imshow(response_scene_arr, cmap<span class="op">=</span><span class="st">"plasma"</span>, origin<span class="op">=</span><span class="st">"lower"</span>)</span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a>axes.axis(<span class="st">"off"</span>)</span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p><img src="../fig/constrained_spherical_deconvolution/frf.png" alt="Fiber Response Function (FRF)" class="figure"><br>
Estimated response function</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>scene.rm(response_actor)</span></code></pre>
</div>
<p>Note that, although fast, the FA threshold might not always be the
best way to find the response function, since it depends on the
diffusion tensor, which has a number of limitations. Similarly,
different bundles are known to have different response functions. More
importantly, it also varies across subjects, and hence it must be
computed on a case basis.</p>
</section><section><h2 class="section-heading" id="step-2--fodf-reconstruction">Step 2. fODF reconstruction<a class="anchor" aria-label="anchor" href="#step-2--fodf-reconstruction"></a>
</h2>
<hr class="half-width">
<p>After estimating a response function, the fODF is reconstructed
through the deconvolution operation. In order to obtain the spherical
representation of the diffusion signal, the order of the Spherical
Harmonics expansion must be specified. The order, <span class="math inline">\(l\)</span>, corresponds to an angular frequency of
the basis function. While the series is infinite, it must be truncated
to a maximum order in practice to be able to represent the diffusion
signal. The maximum order will determine the number of SH coefficients
used. The number of diffusion encoding gradient directions must be at
least as large as the number of coefficients. Hence, the maximum order
<span class="math inline">\(l\_{max}\)</span> is determined by the
equation <span class="math inline">\(R =
(l\_{max}+1)(l\_{max}+2)/2\)</span>, where <span class="math inline">\(R\)</span> is the number of coefficients. For
example, an order <span class="math inline">\(l\_{max} = {4, 6,
8}\)</span> SH series has <span class="math inline">\(R = {15, 28,
45}\)</span> coefficients, respectively. Note the use of even orders:
even order SH functions allow to reconstruct symmetric spherical
functions. Traditionally, even orders have been used motivated by the
fact that the diffusion process is symmetric around the origin.</p>
<p>The CSD is performed in <code>DIPY</code> by calling the
<code>fit</code> method of the CSD model on the diffusion data:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">from</span> dipy.reconst.csdeconv <span class="im">import</span> ConstrainedSphericalDeconvModel</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>sh_order <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>csd_model <span class="op">=</span> ConstrainedSphericalDeconvModel(gtab, response, sh_order<span class="op">=</span>sh_order, convergence<span class="op">=</span><span class="dv">50</span>)</span></code></pre>
</div>
<p>For illustration purposes we will fit only a small portion of the
data representing the splenium of the corpus callosum.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>data_small <span class="op">=</span> data[<span class="dv">40</span>:<span class="dv">80</span>, <span class="dv">40</span>:<span class="dv">80</span>, <span class="dv">45</span>:<span class="dv">55</span>]</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>csd_fit <span class="op">=</span> csd_model.fit(data_small)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>sh_coeffs <span class="op">=</span> csd_fit.shm_coeff</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="co"># Save the SH coefficients</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>nib.save(nib.Nifti1Image(sh_coeffs.astype(np.float32), affine),</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>         os.path.join(out_dir, <span class="st">'sh_coeffs.nii.gz'</span>))</span></code></pre>
</div>
<p>Getting the fODFs from the model fit is straightforward in
<code>DIPY</code>. As a side note, it is worthwhile mentioning that the
orientation distribution recovered by SD methods is also named fODFs to
distinguish from the diffusion ODFs (dODFs) that other reconstruction
methods recover. The former are considered to be a sharper version of
the latter. At times, they are also called Fiber Orientation
Distribution (FOD).</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>csd_odf <span class="op">=</span> csd_fit.odf(default_sphere)</span></code></pre>
</div>
<p>We will now use the <code>generate_anatomical_slice_figure</code>
utility function that allows us to generate three anatomical views
(axial superior, sagittal right and coronal anterior) of the data.</p>
<p>Here we visualize only the central slices of the 40x40x10 region
(i.e. the <code>[40:80, 40:80, 45:55]</code> volume data region) that
has been used.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="im">from</span> utils.visualization_utils <span class="im">import</span> generate_anatomical_slice_figure</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>colormap <span class="op">=</span> <span class="st">"plasma"</span></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a><span class="co"># Build the representation of the data</span></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>fodf_actor <span class="op">=</span> actor.odf_slicer(csd_odf, sphere<span class="op">=</span>default_sphere, scale<span class="op">=</span><span class="fl">0.9</span>,</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>                              norm<span class="op">=</span><span class="va">False</span>, colormap<span class="op">=</span>colormap)</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a><span class="co"># Compute the slices to be shown</span></span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>slices <span class="op">=</span> <span class="bu">tuple</span>(elem <span class="op">//</span> <span class="dv">2</span> <span class="cf">for</span> elem <span class="kw">in</span> data_small.shape[:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a><span class="co"># Generate the figure</span></span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>fig <span class="op">=</span> generate_anatomical_slice_figure(slices, fodf_actor, cmap<span class="op">=</span>colormap)</span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a>fig.savefig(os.path.join(out_dir, <span class="st">"csd_odfs.png"</span>), dpi<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a>            bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p><img src="../fig/constrained_spherical_deconvolution/csd_odfs.png" alt="CSD ODFs" class="figure"><br>
CSD ODFs.</p>
<p>The peak directions (maxima) of the fODFs can be found from the
fODFs. For this purpose, <code>DIPY</code> offers the
<code>peaks_from_model</code> method.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="im">from</span> dipy.direction <span class="im">import</span> peaks_from_model</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="im">from</span> dipy.io.peaks <span class="im">import</span> reshape_peaks_for_visualization</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>csd_peaks <span class="op">=</span> peaks_from_model(model<span class="op">=</span>csd_model,</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>                             data<span class="op">=</span>data_small,</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>                             sphere<span class="op">=</span>default_sphere,</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>                             relative_peak_threshold<span class="op">=</span><span class="fl">.5</span>,</span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a>                             min_separation_angle<span class="op">=</span><span class="dv">25</span>,</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>                             parallel<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a><span class="co"># Save the peaks</span></span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a>nib.save(nib.Nifti1Image(reshape_peaks_for_visualization(csd_peaks),</span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a>                         affine), os.path.join(out_dir, <span class="st">'peaks.nii.gz'</span>))</span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a>peak_indices <span class="op">=</span> csd_peaks.peak_indices</span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a>nib.save(nib.Nifti1Image(peak_indices, affine), os.path.join(out_dir,</span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a>    <span class="st">'peaks_indices.nii.gz'</span>))</span></code></pre>
</div>
<p>We can visualize them as usual using <code>FURY</code>:</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># Build the representation of the data</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>peaks_actor <span class="op">=</span> actor.peak_slicer(csd_peaks.peak_dirs, csd_peaks.peak_values)</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="co"># Generate the figure</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>fig <span class="op">=</span> generate_anatomical_slice_figure(slices, peaks_actor, cmap<span class="op">=</span>colormap)</span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>fig.savefig(os.path.join(out_dir, <span class="st">"csd_peaks.png"</span>), dpi<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a>    bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p><img src="../fig/constrained_spherical_deconvolution/csd_peaks.png" alt="CSD peaks" class="figure"><br>
CSD Peaks.</p>
<p>We can finally visualize both the fODFs and peaks in the same
space.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>fodf_actor.GetProperty().SetOpacity(<span class="fl">0.4</span>)</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="co"># Generate the figure</span></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>fig <span class="op">=</span> generate_anatomical_slice_figure(slices, peaks_actor, fodf_actor,</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>                                       cmap<span class="op">=</span>colormap)</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>fig.savefig(os.path.join(out_dir, <span class="st">"csd_peaks_fodfs.png"</span>), dpi<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a>            bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p><img src="../fig/constrained_spherical_deconvolution/csd_peaks_fodfs.png" alt="CSD peaks and fODFs" class="figure"><br>
CSD Peaks and ODFs.</p>
</section><section><h2 class="section-heading" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<hr class="half-width">
<p>.. [Tournier2007] J-D. Tournier, F. Calamante and A. Connelly,
“Robust determination of the fibre orientation distribution in diffusion
MRI: Non-negativity constrained super-resolved spherical deconvolution”,
Neuroimage, vol. 35, no. 4, pp. 1459-1472, 2007.</p>
<div id="exercise-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise-1" class="callout-inner">
<h3 class="callout-title">Exercise 1</h3>
<div class="callout-content">
<p>Simulate the ODF for two fibre populations with crossing angles of
90, 60, 45, 30, and 20 degrees. We have included helpful hints and code
below to help you get started.</p>
<p>Helpful hints:</p>
<ul>
<li>To set the angle between tensors, use
<code>[(0, 0), (angle, 0)]</code>.</li>
<li>You may need to use a higher resolution sphere than
<code>default_sphere</code>.</li>
<li>You may need to rotate the scene to visualize the ODFs.</li>
<li>Below is some code to simulate multiple fibre orientations:</li>
</ul>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="im">from</span> dipy.sims.voxel <span class="im">import</span> multi_tensor_odf</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a><span class="co"># Eigenvalues for multiple orientations</span></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>mevals <span class="op">=</span> np.array(([<span class="fl">0.0015</span>, <span class="fl">0.00015</span>, <span class="fl">0.00015</span>], [<span class="fl">0.0015</span>, <span class="fl">0.00015</span>, <span class="fl">0.00015</span>]))</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a><span class="co"># Set fractional value of each tensor</span></span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>fractions <span class="op">=</span> [<span class="dv">50</span>, <span class="dv">50</span>]</span></code></pre>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>We will first simulate the ODFs for the different crossing
angles:</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a><span class="im">from</span> dipy.data <span class="im">import</span> get_sphere</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a><span class="im">from</span> dipy.sims.voxel <span class="im">import</span> multi_tensor_odf</span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a><span class="co"># Set eigenvalues for tensors</span></span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a>mevals <span class="op">=</span> np.array(([<span class="fl">0.0015</span>, <span class="fl">0.00015</span>, <span class="fl">0.00015</span>], [<span class="fl">0.0015</span>, <span class="fl">0.00015</span>, <span class="fl">0.00015</span>]))</span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a><span class="co"># Set fraction for each tensor </span></span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a>fractions <span class="op">=</span> [<span class="dv">50</span>, <span class="dv">50</span>]</span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" tabindex="-1"></a><span class="co"># Create a list of the crossing angles to be simulated</span></span>
<span id="cb17-13"><a href="#cb17-13" tabindex="-1"></a>angles <span class="op">=</span> [<span class="dv">90</span>, <span class="dv">60</span>, <span class="dv">45</span>, <span class="dv">30</span>, <span class="dv">20</span>]</span>
<span id="cb17-14"><a href="#cb17-14" tabindex="-1"></a></span>
<span id="cb17-15"><a href="#cb17-15" tabindex="-1"></a>odf <span class="op">=</span> []</span>
<span id="cb17-16"><a href="#cb17-16" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" tabindex="-1"></a><span class="co"># Simulate ODFs of different angles</span></span>
<span id="cb17-18"><a href="#cb17-18" tabindex="-1"></a><span class="cf">for</span> angle <span class="kw">in</span> angles:</span>
<span id="cb17-19"><a href="#cb17-19" tabindex="-1"></a>    _angles <span class="op">=</span> [(<span class="dv">0</span>, <span class="dv">0</span>), (angle, <span class="dv">0</span>)]</span>
<span id="cb17-20"><a href="#cb17-20" tabindex="-1"></a>    _odf <span class="op">=</span> multi_tensor_odf(get_sphere(</span>
<span id="cb17-21"><a href="#cb17-21" tabindex="-1"></a>        <span class="st">"repulsion724"</span>).vertices, mevals, _angles, fractions)</span>
<span id="cb17-22"><a href="#cb17-22" tabindex="-1"></a>    odf.append(_odf)</span></code></pre>
</div>
<p>We are now able to visualize and save to disk a screenshot of each
ODF crossing. As it can be seen, as the crossing angle becomes smaller,
distinguishing the underlying fiber orientations becomes harder: an ODF
might be unable to resolve different fiber populations at such
crossings, and be only able to indicate a single orientation. This has
an impact on tractography, since the tracking procedure will only be
able to propagate streamlines according to peaks retrieved by the ODFs.
Also, note that thi problem is worsened by the presence of noise in real
diffusion data.</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a><span class="im">from</span> fury <span class="im">import</span> window, actor</span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a><span class="co"># Create the output directory to store the image</span></span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a>out_dir <span class="op">=</span> <span class="st">'../../data/ds000221/derivatives/dwi/reconstruction/exercise/dwi/'</span></span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(out_dir):</span>
<span id="cb18-9"><a href="#cb18-9" tabindex="-1"></a>    os.makedirs(out_dir)</span>
<span id="cb18-10"><a href="#cb18-10" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="bu">len</span>(angles), figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">2</span>))</span>
<span id="cb18-12"><a href="#cb18-12" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" tabindex="-1"></a><span class="co"># Visualize the simulated ODFs of different angles</span></span>
<span id="cb18-14"><a href="#cb18-14" tabindex="-1"></a><span class="cf">for</span> ix, (_odf, angle) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(odf, angles)):</span>
<span id="cb18-15"><a href="#cb18-15" tabindex="-1"></a>    scene <span class="op">=</span> window.Scene()</span>
<span id="cb18-16"><a href="#cb18-16" tabindex="-1"></a>    odf_actor <span class="op">=</span> actor.odf_slicer(_odf[<span class="va">None</span>, <span class="va">None</span>, <span class="va">None</span>, :], sphere<span class="op">=</span>get_sphere(<span class="st">"repulsion724"</span>),</span>
<span id="cb18-17"><a href="#cb18-17" tabindex="-1"></a>                                 colormap<span class="op">=</span><span class="st">'plasma'</span>)</span>
<span id="cb18-18"><a href="#cb18-18" tabindex="-1"></a>    odf_actor.RotateX(<span class="dv">90</span>)</span>
<span id="cb18-19"><a href="#cb18-19" tabindex="-1"></a>    scene.add(odf_actor)</span>
<span id="cb18-20"><a href="#cb18-20" tabindex="-1"></a>    odf_scene_arr <span class="op">=</span> window.snapshot(</span>
<span id="cb18-21"><a href="#cb18-21" tabindex="-1"></a>        scene, fname<span class="op">=</span>os.path.join(out_dir, <span class="st">'odf_</span><span class="sc">%d</span><span class="st">_angle.png'</span> <span class="op">%</span> angle), size<span class="op">=</span>(<span class="dv">200</span>, <span class="dv">200</span>),</span>
<span id="cb18-22"><a href="#cb18-22" tabindex="-1"></a>        offscreen<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-23"><a href="#cb18-23" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" tabindex="-1"></a>    axes[ix].imshow(odf_scene_arr, cmap<span class="op">=</span><span class="st">"plasma"</span>, origin<span class="op">=</span><span class="st">"lower"</span>)</span>
<span id="cb18-25"><a href="#cb18-25" tabindex="-1"></a>    axes[ix].set_title(<span class="st">"</span><span class="sc">%d</span><span class="st"> deg"</span> <span class="op">%</span> angle)</span>
<span id="cb18-26"><a href="#cb18-26" tabindex="-1"></a>    axes[ix].axis(<span class="st">"off"</span>)</span>
<span id="cb18-27"><a href="#cb18-27" tabindex="-1"></a></span>
<span id="cb18-28"><a href="#cb18-28" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p><img src="../fig/constrained_spherical_deconvolution/odf_multiple_angles.png" alt="ODFs of differing crossing angles" class="figure"><br>
ODFs of different crossing angles.</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>CSD uses the information along more gradient encoding
directions</li>
<li>It allows to resolve complex fiber configurations, such as
crossings</li>
</ul>
</div>
</div>
</div>
<!-- Workshop-specific links -->
</section></section><section id="aio-tractography"><p>Content from <a href="tractography.html">Tractography</a></p>
<hr>
<p>Last updated on 2024-02-18 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-dMRI/edit/main/episodes/tractography.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 140 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What information can dMRI provide at the long range level?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Present different long range orientation reconstruction methods</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="tractography">Tractography<a class="anchor" aria-label="anchor" href="#tractography"></a>
</h2>
<hr class="half-width">
<p>The local fiber orientation reconstruction can be used to map the
voxel-wise fiber orientations to white matter long range structural
connectivity. Tractography is a fiber tracking technique that studies
how the local orientations can be integrated to provide an estimation of
the white matter fibers connecting structurally two regions in the white
matter.</p>
<p>Tractography models axonal trajectories as geometrical entities
called <em>streamlines</em> from local directional information.
Tractograhy essentially uses an integral equation involving a set of
discrete local directions to numerically find the curve (i.e. the
streamline) that joins them. The streamlines generated by a tractography
method and the required meta-data are usually saved into files called
<em>tractograms</em>.</p>
<p>The following is a list of the main families of tractography methods
in chronological order:</p>
<ul>
<li>Local tractography (Conturo et al. 1999, Mori et al. 1999, Basser et
al. 2000).</li>
<li>Global tracking (Mangin et al. 2002)</li>
<li>Particle Filtering Tractography (PFT) (Girard et al. 2014)</li>
<li>Parallel Transport Tractography (PTT) (Aydogan et al., 2019)</li>
</ul>
<p>Local tractography methods and PFT can use two approaches to
propagate the streamlines:</p>
<ul>
<li>Deterministic: propagates streamlines consistently using the same
propagation direction.</li>
<li>Probabilistic: uses a distribution function to sample from in order
to decide on the next propagation direction at each step.</li>
</ul>
<p>Several algorithms exist to perform local tracking, depending on the
local orientation construct used or the order of the integration being
performed, among others: FACT (Mori et al. 1999), EuDX (Garyfallidis
2012), iFOD1 (Tournier et al. 2012) / iFOD2 (Tournier et al. 2010), and
SD_STREAM (Tournier et al. 2012) are some of those. Different strategies
to reduce the uncertainty (or missed configurations) on the tracking
results have also been proposed (e.g. Ensemble Tractography (Takemura et
al. 2016), Bootstrap Tractography (Lazar et al. 2005)).</p>
<p>Tractography methods suffer from a number of known biases and
limitations, generally yielding tractograms containing a large number of
prematurely stopped streamlines and invalid connections, among others.
This results in a hard trade-off between sensitivity and specificity
(usually measured in the form of bundle overlap and overreach)
(Maier-Hein et al. 2017).</p>
<p>Several enhancements to the above frameworks have been proposed,
usually based on incorporating some <em>a priori</em> knowledge
(e.g. Anatomically-Constrained Tractography (ACT) (Smith et al. 2012),
Structure Tensor Informed Fiber Tractography (STIFT) (Kleinnijenhuis et
al. 2012), Surface-enhanced Tractography (SET) (St-Onge et al. 2018),
Bundle-Specific Tractography (BST) (Rheault et al., 2019), etc.).</p>
<p>In the recent years, many deep learning methods have been proposed to
map the local orientation reconstruction (or directly the diffusion MRI
data) to long range white matter connectivity.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Provides an estimation of the long range underlying fiber
arrangement</li>
<li>Tractography is central to estimate and provide measures of the
white matter neuroanatomy</li>
</ul>
</div>
</div>
</div>
<!-- Workshop-specific links -->
</section></section><section id="aio-local_tractography"><p>Content from <a href="local_tractography.html">Local tractography</a></p>
<hr>
<p>Last updated on 2024-02-18 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-dMRI/edit/main/episodes/local_tractography.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What input data does a local tractography method require?</li>
<li>Which steps does a local tractography method follow?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the basic mathematical principle behind local
tractography</li>
<li>Be able to identify the necessary elements for a local tractography
method</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="local-tractography">Local tractography<a class="anchor" aria-label="anchor" href="#local-tractography"></a>
</h2>
<hr class="half-width">
<p>Local tractography algorithms follow 2 general principles:</p>
<ol style="list-style-type: decimal">
<li>Estimate the fiber orientation, and</li>
<li>Follow along these orientations to generate/propagate the
streamline.</li>
</ol>
<p>Streamline propagation is, in essence, a numerical analysis
integration problem. The problem lies in finding a curve that joins a
set of discrete local directions. As such, it takes the form of a
differential equation problem of the form: <img src="../fig/local_tractography/streamline_propagation_diff_equation.png" alt="Streamline propagation equation" class="figure"><br>
Streamline propagation differential equation</p>
<p>where the curve <span class="math inline">\(r(s)\)</span> needs to be
solved for.</p>
<p>To perform conventional local fiber tracking, three things are needed
beyond the propagation method itself:</p>
<ol style="list-style-type: decimal">
<li>A method for getting local orientation directions from a diffusion
MRI dataset (e.g. diffusion tensor).</li>
<li>A set of seeds from which to begin tracking.</li>
<li>A method for identifying when to stop tracking.</li>
</ol>
<p>Different alternatives have been proposed for each step depending on
the available data or computed features.</p>
<p>When further context data (e.g. tissue information) is added to the
above to perform the tracking process, the tracking method is considered
to fall into the <em>Anatomically-Constrained Tractography</em> (Smith
et al. 2012) family of methods.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Local tractography uses local orientation information obtained from
diffusion MRI data</li>
<li>Tractography requires seeds to begin tracking and a stopping
criterion for termination</li>
</ul>
</div>
</div>
</div>
<!-- Workshop-specific links -->
</section></section><section id="aio-deterministic_tractography"><p>Content from <a href="deterministic_tractography.html">Deterministic tractography</a></p>
<hr>
<p>Last updated on 2024-02-18 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-dMRI/edit/main/episodes/deterministic_tractography.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What computations does a deterministic tractography require?</li>
<li>How can we visualize the streamlines generated by a tractography
method?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Be able to perform deterministic tracking on diffusion MRI data</li>
<li>Familiarize with the data entities of a tractogram</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="deterministic-tractography">Deterministic tractography<a class="anchor" aria-label="anchor" href="#deterministic-tractography"></a>
</h2>
<hr class="half-width">
<p>Deterministic tractography algorithms perform tracking of streamlines
by following a predictable path, such as following the primary diffusion
direction.</p>
<p>In order to demonstrate how to perform deterministic tracking on a
diffusion MRI dataset, we will build from the preprocessing presented in
a previous episode and compute the diffusion tensor.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> os </span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> nibabel <span class="im">as</span> nib</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">from</span> bids.layout <span class="im">import</span> BIDSLayout</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">from</span> dipy.io.gradients <span class="im">import</span> read_bvals_bvecs</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="im">from</span> dipy.core.gradients <span class="im">import</span> gradient_table</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>dwi_layout <span class="op">=</span> BIDSLayout(<span class="st">"../../data/ds000221/derivatives/uncorrected_topup_eddy"</span>, validate<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>gradient_layout <span class="op">=</span> BIDSLayout(<span class="st">"../../data/ds000221/"</span>, validate<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>subj <span class="op">=</span> <span class="st">'010006'</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>dwi_fname <span class="op">=</span> dwi_layout.get(subject<span class="op">=</span>subj, suffix<span class="op">=</span><span class="st">'dwi'</span>, extension<span class="op">=</span><span class="st">'.nii.gz'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>bvec_fname <span class="op">=</span> dwi_layout.get(subject<span class="op">=</span>subj, extension<span class="op">=</span><span class="st">'.eddy_rotated_bvecs'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>bval_fname <span class="op">=</span> gradient_layout.get(subject<span class="op">=</span>subj, suffix<span class="op">=</span><span class="st">'dwi'</span>, extension<span class="op">=</span><span class="st">'.bval'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>dwi_img <span class="op">=</span> nib.load(dwi_fname)</span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>affine <span class="op">=</span> dwi_img.affine</span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a>bvals, bvecs <span class="op">=</span> read_bvals_bvecs(bval_fname, bvec_fname)</span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a>gtab <span class="op">=</span> gradient_table(bvals, bvecs)</span></code></pre>
</div>
<p>We will now create a mask and constrain the fitting within the
mask.</p>
<div id="tractography-run-times" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="tractography-run-times" class="callout-inner">
<h3 class="callout-title">Tractography run times</h3>
<div class="callout-content">
<p>Note that many steps in the streamline propagation procedure are
computationally intensive, and thus may take a while to complete.</p>
</div>
</div>
</div>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">import</span> dipy.reconst.dti <span class="im">as</span> dti</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">from</span> dipy.segment.mask <span class="im">import</span> median_otsu</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>dwi_data <span class="op">=</span> dwi_img.get_fdata()</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>dwi_data, dwi_mask <span class="op">=</span> median_otsu(dwi_data, vol_idx<span class="op">=</span>[<span class="dv">0</span>], numpass<span class="op">=</span><span class="dv">1</span>)  <span class="co"># Specify the volume index to the b0 volumes</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>dti_model <span class="op">=</span> dti.TensorModel(gtab)</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>dti_fit <span class="op">=</span> dti_model.fit(dwi_data, mask<span class="op">=</span>dwi_mask)  <span class="co"># This step may take a while</span></span></code></pre>
</div>
<p>We will perform tracking using a deterministic algorithm on tensor
fields via <code>EuDX</code> <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3518823/" class="external-link">(Garyfallidis
<em>et al.</em>, 2012)</a>. <code>EuDX</code> makes use of the primary
direction of the diffusion tensor to propagate streamlines from voxel to
voxel and a stopping criteria from the fractional anisotropy (FA).</p>
<p>We will first get the FA map and eigenvectors from our tensor
fitting. In the background of the FA map, the fitting may not be
accurate as all of the measured signal is primarily noise and it is
possible that values of NaNs (not a number) may be found in the FA map.
We can remove these using <code>numpy</code> to find and set these
voxels to 0.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Create the directory to save the results</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>out_dir <span class="op">=</span> <span class="ss">f"../../data/ds000221/derivatives/dwi/tractography/sub-</span><span class="sc">{</span>subj<span class="sc">}</span><span class="ss">/ses-01/dwi/"</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(out_dir):</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>    os.makedirs(out_dir)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>fa_img <span class="op">=</span> dti_fit.fa</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>evecs_img <span class="op">=</span> dti_fit.evecs</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>fa_img[np.isnan(fa_img)] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="co"># Save the FA</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>fa_nii <span class="op">=</span> nib.Nifti1Image(fa_img.astype(np.float32), affine)</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>nib.save(fa_nii, os.path.join(out_dir, <span class="st">'fa.nii.gz'</span>))</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="co"># Plot the FA</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> ndimage  <span class="co"># To rotate image for visualization purposes</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a>ax[<span class="dv">0</span>].imshow(ndimage.rotate(fa_img[:, fa_img.shape[<span class="dv">1</span>]<span class="op">//</span><span class="dv">2</span>, :], <span class="dv">90</span>, reshape<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a>ax[<span class="dv">1</span>].imshow(ndimage.rotate(fa_img[fa_img.shape[<span class="dv">0</span>]<span class="op">//</span><span class="dv">2</span>, :, :], <span class="dv">90</span>, reshape<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a>ax[<span class="dv">2</span>].imshow(ndimage.rotate(fa_img[:, :, fa_img.shape[<span class="op">-</span><span class="dv">1</span>]<span class="op">//</span><span class="dv">2</span>], <span class="dv">90</span>, reshape<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a>fig.savefig(os.path.join(out_dir, <span class="st">"fa.png"</span>), dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/deterministic_tractography/fa.png" alt="FA" class="figure mx-auto d-block"></figure><p>One of the inputs of <code>EuDX</code> is the discretized voxel
directions on a unit sphere. Therefore, it is necessary to discretize
the eigenvectors before providing them to <code>EuDX</code>. We will use
an evenly distributed sphere of 362 points using the
<code>get_sphere</code> function.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="im">from</span> dipy.data <span class="im">import</span> get_sphere</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>sphere <span class="op">=</span> get_sphere(<span class="st">'symmetric362'</span>)</span></code></pre>
</div>
<p>We will determine the indices representing the discretized directions
of the peaks by providing as input, our tensor model, the diffusion
data, the sphere, and a mask to apply the processing to. Additionally,
we will set the minimum angle between directions, the maximum number of
peaks to return (1 for the tensor model), and the relative peak
threshold (returning peaks greater than this value).</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">from</span> dipy.direction <span class="im">import</span> peaks_from_model</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>peak_indices <span class="op">=</span> peaks_from_model(</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>    model<span class="op">=</span>dti_model, data<span class="op">=</span>dwi_data, sphere<span class="op">=</span>sphere, relative_peak_threshold<span class="op">=</span><span class="fl">.2</span>,</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>    min_separation_angle<span class="op">=</span><span class="dv">25</span>, mask<span class="op">=</span>dwi_mask, npeaks<span class="op">=</span><span class="dv">2</span>)</span></code></pre>
</div>
<p>Additionally, we will apply a stopping criterion for our tracking
based on the FA map. That is, we will stop our tracking when we reach a
voxel where FA is below 0.2.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="im">from</span> dipy.tracking.stopping_criterion <span class="im">import</span> ThresholdStoppingCriterion</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>stopping_criterion <span class="op">=</span> ThresholdStoppingCriterion(fa_img, <span class="fl">.2</span>)</span></code></pre>
</div>
<p>We will also need to specify where to “seed” (begin) the fiber
tracking. Generally, the seeds chosen will depend on the pathways one is
interested in modelling. In this example, we will create a seed mask
from the FA map thresholding above our stopping criterion.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">from</span> dipy.tracking <span class="im">import</span> utils</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>seed_mask <span class="op">=</span> fa_img.copy()</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>seed_mask[seed_mask <span class="op">&gt;=</span> <span class="fl">0.2</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>seed_mask[seed_mask <span class="op">&lt;</span> <span class="fl">0.2</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>seeds <span class="op">=</span> utils.seeds_from_mask(seed_mask, affine<span class="op">=</span>affine, density<span class="op">=</span><span class="dv">1</span>)</span></code></pre>
</div>
<p>Now, we can apply the tracking algorithm!</p>
<p>As mentioned previously, <code>EuDX</code> is the fiber tracking
algorithm that we will be using. The most important parameters to
include are the indices representing the discretized directions of the
peaks (<code>peak_indices</code>), the stopping criterion, the seeds,
the affine transformation, and the step sizes to take when tracking!</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">from</span> dipy.tracking.local_tracking <span class="im">import</span> LocalTracking</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="im">from</span> dipy.tracking.streamline <span class="im">import</span> Streamlines</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co"># Initialize local tracking - computation happens in the next step.</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>streamlines_generator <span class="op">=</span> LocalTracking(</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>    peak_indices, stopping_criterion, seeds, affine<span class="op">=</span>affine, step_size<span class="op">=</span><span class="fl">.5</span>)</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co"># Generate streamlines object</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>streamlines <span class="op">=</span> Streamlines(streamlines_generator)</span></code></pre>
</div>
<p>We just created a deterministic set of streamlines using the
<code>EuDX</code> algorithm mapping the human brain connectome
(tractography). We can save the streamlines as a <code>Trackvis</code>
file so it can be loaded into other software for visualization or
further analysis. To do so, we need to save the tractogram state using
<code>StatefulTractogram</code> and <code>save_tractogram</code> to save
the file. Note that we will have to specify the space to save the
tractogram in.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">from</span> dipy.io.stateful_tractogram <span class="im">import</span> Space, StatefulTractogram</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="im">from</span> dipy.io.streamline <span class="im">import</span> save_tractogram</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>sft <span class="op">=</span> StatefulTractogram(streamlines, dwi_img, Space.RASMM)</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="co"># Save the tractogram</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>save_tractogram(sft, os.path.join(out_dir, <span class="st">"tractogram_deterministic_EuDX.trk"</span>))</span></code></pre>
</div>
<p>We can then generate the streamlines 3D scene using the
<code>FURY</code> python package, and visualize the scene’s contents
with <code>Matplotlib</code>.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="im">from</span> fury <span class="im">import</span> actor, colormap</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="im">from</span> utils.visualization_utils <span class="im">import</span> generate_anatomical_volume_figure</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="co"># Plot the tractogram</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="co"># Build the representation of the data</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>streamlines_actor <span class="op">=</span> actor.line(streamlines, colormap.line_colors(streamlines))</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a><span class="co"># Generate the figure</span></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>fig <span class="op">=</span> generate_anatomical_volume_figure(streamlines_actor)</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>fig.savefig(os.path.join(out_dir, <span class="st">"tractogram_deterministic_EuDX.png"</span>),</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>            dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/deterministic_tractography/tractogram_deterministic_EuDX.png" alt="EuDX Determinsitic Tractography" class="figure mx-auto d-block"></figure><div id="exercise-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise-1" class="callout-inner">
<h3 class="callout-title">Exercise 1</h3>
<div class="callout-content">
<p>In this episode, we applied a threshold stopping criteria to stop
tracking when we reach a voxel where FA is below 0.2. There are also
other stopping criteria available. We encourage you to read the
<code>DIPY</code> documentation about the others. For this exercise,
repeat the tractography, but apply a binary stopping criteria
(<code>BinaryStoppingCriterion</code>) using the seed mask. Visualize
the tractogram!</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="im">import</span> nibabel <span class="im">as</span> nib</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a><span class="im">from</span> bids.layout <span class="im">import</span> BIDSLayout</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a><span class="im">from</span> dipy.io.gradients <span class="im">import</span> read_bvals_bvecs</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a><span class="im">from</span> dipy.core.gradients <span class="im">import</span> gradient_table</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a><span class="im">from</span> dipy.data <span class="im">import</span> get_sphere</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a><span class="im">from</span> dipy.direction <span class="im">import</span> peaks_from_model</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a><span class="im">import</span> dipy.reconst.dti <span class="im">as</span> dti</span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a><span class="im">from</span> dipy.segment.mask <span class="im">import</span> median_otsu</span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a><span class="im">from</span> dipy.tracking <span class="im">import</span> utils</span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a><span class="im">from</span> dipy.tracking.local_tracking <span class="im">import</span> LocalTracking</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a><span class="im">from</span> dipy.tracking.streamline <span class="im">import</span> Streamlines</span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a></span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a><span class="im">from</span> utils.visualization_utils <span class="im">import</span> generate_anatomical_volume_figure</span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a><span class="im">from</span> fury <span class="im">import</span> actor, colormap</span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a>dwi_layout <span class="op">=</span> BIDSLayout(<span class="st">"../../data/ds000221/derivatives/uncorrected_topup_eddy"</span>, validate<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-23"><a href="#cb11-23" tabindex="-1"></a>gradient_layout <span class="op">=</span> BIDSLayout(<span class="st">"../../data/ds000221/"</span>, <span class="op">&gt;</span> <span class="op">&gt;</span> validate<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-24"><a href="#cb11-24" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" tabindex="-1"></a><span class="co"># Get subject data</span></span>
<span id="cb11-26"><a href="#cb11-26" tabindex="-1"></a>subj <span class="op">=</span> <span class="st">'010006'</span></span>
<span id="cb11-27"><a href="#cb11-27" tabindex="-1"></a>dwi_fname <span class="op">=</span> dwi_layout.get(subject<span class="op">=</span>subj, suffix<span class="op">=</span><span class="st">'dwi'</span>, extension<span class="op">=</span><span class="st">'.nii.gz'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb11-28"><a href="#cb11-28" tabindex="-1"></a>bvec_fname <span class="op">=</span> dwi_layout.get(subject<span class="op">=</span>subj, extension<span class="op">=</span><span class="st">'.eddy_rotated_bvecs'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb11-29"><a href="#cb11-29" tabindex="-1"></a>bval_fname <span class="op">=</span> gradient_layout.get(subject<span class="op">=</span>subj, suffix<span class="op">=</span><span class="st">'dwi'</span>, extension<span class="op">=</span><span class="st">'.bval'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb11-30"><a href="#cb11-30" tabindex="-1"></a></span>
<span id="cb11-31"><a href="#cb11-31" tabindex="-1"></a>dwi_img <span class="op">=</span> nib.load(dwi_fname)</span>
<span id="cb11-32"><a href="#cb11-32" tabindex="-1"></a>affine <span class="op">=</span> dwi_img.affine</span>
<span id="cb11-33"><a href="#cb11-33" tabindex="-1"></a></span>
<span id="cb11-34"><a href="#cb11-34" tabindex="-1"></a>bvals, bvecs <span class="op">=</span> read_bvals_bvecs(bval_fname, bvec_fname)</span>
<span id="cb11-35"><a href="#cb11-35" tabindex="-1"></a>gtab <span class="op">=</span> gradient_table(bvals, bvecs)</span>
<span id="cb11-36"><a href="#cb11-36" tabindex="-1"></a></span>
<span id="cb11-37"><a href="#cb11-37" tabindex="-1"></a>dwi_data <span class="op">=</span> dwi_img.get_fdata()</span>
<span id="cb11-38"><a href="#cb11-38" tabindex="-1"></a>dwi_data, dwi_mask <span class="op">=</span> median_otsu(dwi_data, vol_idx<span class="op">=</span>[<span class="dv">0</span>], numpass<span class="op">=</span><span class="dv">1</span>)  <span class="co"># Specify the volume index to the b0 volumes</span></span>
<span id="cb11-39"><a href="#cb11-39" tabindex="-1"></a></span>
<span id="cb11-40"><a href="#cb11-40" tabindex="-1"></a><span class="co"># Fit tensor and compute FA map</span></span>
<span id="cb11-41"><a href="#cb11-41" tabindex="-1"></a>dti_model <span class="op">=</span> dti.TensorModel(gtab)</span>
<span id="cb11-42"><a href="#cb11-42" tabindex="-1"></a>dti_fit <span class="op">=</span> dti_model.fit(dwi_data, mask<span class="op">=</span>dwi_mask)  </span>
<span id="cb11-43"><a href="#cb11-43" tabindex="-1"></a>fa_img <span class="op">=</span> dti_fit.fa</span>
<span id="cb11-44"><a href="#cb11-44" tabindex="-1"></a>evecs_img <span class="op">=</span> dti_fit.evecs</span>
<span id="cb11-45"><a href="#cb11-45" tabindex="-1"></a></span>
<span id="cb11-46"><a href="#cb11-46" tabindex="-1"></a>sphere <span class="op">=</span> get_sphere(<span class="st">'symmetric362'</span>)</span>
<span id="cb11-47"><a href="#cb11-47" tabindex="-1"></a>peak_indices <span class="op">=</span> peaks_from_model(</span>
<span id="cb11-48"><a href="#cb11-48" tabindex="-1"></a>       model<span class="op">=</span>dti_model, data<span class="op">=</span>dwi_data, sphere<span class="op">=</span>sphere,</span>
<span id="cb11-49"><a href="#cb11-49" tabindex="-1"></a>       relative_peak_threshold<span class="op">=</span><span class="fl">.2</span>, min_separation_angle<span class="op">=</span><span class="dv">25</span>, mask<span class="op">=</span>dwi_mask,</span>
<span id="cb11-50"><a href="#cb11-50" tabindex="-1"></a>       npeaks<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb11-51"><a href="#cb11-51" tabindex="-1"></a></span>
<span id="cb11-52"><a href="#cb11-52" tabindex="-1"></a><span class="co"># Create a binary seed mask</span></span>
<span id="cb11-53"><a href="#cb11-53" tabindex="-1"></a>seed_mask <span class="op">=</span> fa_img.copy()</span>
<span id="cb11-54"><a href="#cb11-54" tabindex="-1"></a>seed_mask[seed_mask <span class="op">&gt;=</span> <span class="fl">0.2</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb11-55"><a href="#cb11-55" tabindex="-1"></a>seed_mask[seed_mask <span class="op">&lt;</span> <span class="fl">0.2</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-56"><a href="#cb11-56" tabindex="-1"></a></span>
<span id="cb11-57"><a href="#cb11-57" tabindex="-1"></a>seeds <span class="op">=</span> utils.seeds_from_mask(seed_mask, affine<span class="op">=</span>affine, density<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-58"><a href="#cb11-58" tabindex="-1"></a></span>
<span id="cb11-59"><a href="#cb11-59" tabindex="-1"></a><span class="co"># Set stopping criteria</span></span>
<span id="cb11-60"><a href="#cb11-60" tabindex="-1"></a>stopping_criterion <span class="op">=</span> BinaryStoppingCriterion(seed_mask<span class="op">==</span><span class="dv">1</span>)</span>
<span id="cb11-61"><a href="#cb11-61" tabindex="-1"></a></span>
<span id="cb11-62"><a href="#cb11-62" tabindex="-1"></a><span class="co"># Perform tracking</span></span>
<span id="cb11-63"><a href="#cb11-63" tabindex="-1"></a>streamlines_generator <span class="op">=</span> LocalTracking(</span>
<span id="cb11-64"><a href="#cb11-64" tabindex="-1"></a>    peak_indices, stopping_criterion, seeds, affine<span class="op">=</span>affine, step_size<span class="op">=</span><span class="fl">.5</span>)</span>
<span id="cb11-65"><a href="#cb11-65" tabindex="-1"></a>streamlines <span class="op">=</span> Streamlines(streamlines_generator)</span>
<span id="cb11-66"><a href="#cb11-66" tabindex="-1"></a></span>
<span id="cb11-67"><a href="#cb11-67" tabindex="-1"></a><span class="co"># Plot the tractogram</span></span>
<span id="cb11-68"><a href="#cb11-68" tabindex="-1"></a><span class="co"># Build the representation of the data</span></span>
<span id="cb11-69"><a href="#cb11-69" tabindex="-1"></a>streamlines_actor <span class="op">=</span> actor.line(streamlines, colormap.line_colors(streamlines))</span>
<span id="cb11-70"><a href="#cb11-70" tabindex="-1"></a></span>
<span id="cb11-71"><a href="#cb11-71" tabindex="-1"></a><span class="co"># Generate the figure</span></span>
<span id="cb11-72"><a href="#cb11-72" tabindex="-1"></a>fig <span class="op">=</span> generate_anatomical_volume_figure(streamlines_actor)</span>
<span id="cb11-73"><a href="#cb11-73" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/deterministic_tractography/tractogram_deterministic_ex1.png" alt="Binary Stopping Criterion Tractography" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
</div>
<div id="exercise-2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise-2" class="callout-inner">
<h3 class="callout-title">Exercise 2</h3>
<div class="callout-content">
<p>As an additional challenge, set the color of the streamlines to
display the values of the FA map and change the opacity to
<code>0.05</code>. You may need to transform the streamlines from world
coordinates to the subject’s native space using
<code>transform_streamlines</code> from
<code>dipy.tracking.streamline</code>.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="im">from</span> fury <span class="im">import</span> actor</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="im">from</span> dipy.tracking.streamline <span class="im">import</span> transform_streamlines</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a><span class="im">from</span> utils.visualizations_utils <span class="im">import</span> generate_anatomical_volume_figure</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt </span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>streamlines_native <span class="op">=</span> transform_streamlines(streamlines, np.linalg.inv(affine))</span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>streamlines_actor <span class="op">=</span> actor.line(streamlines_native, fa_img, opacity<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>fig <span class="op">=</span> generate_anatomical_volume_figure(streamlines_actor)</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/deterministic_tractography/tractogram_deterministic_fa.png" alt="FA Mapped Tractography" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Deterministic tractography methods perform tracking in a predictable
way</li>
</ul>
</div>
</div>
</div>
<!-- Workshop-specific links -->
</section></section><section id="aio-probabilistic_tractography"><p>Content from <a href="probabilistic_tractography.html">Probabilistic tractography</a></p>
<hr>
<p>Last updated on 2024-02-18 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-dMRI/edit/main/episodes/probabilistic_tractography.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 35 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>Why do we need tractography algorithms beyond the deterministic
ones?</li>
<li>How is probabilistic tractography different from deterministic
tractography?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the principles behind a probabilistic tractography
algorithm</li>
<li>Understand the aspects involved when analyzing the tractogram
computed using a probabilistic algorithm</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="probabilistic-tractography">Probabilistic tractography<a class="anchor" aria-label="anchor" href="#probabilistic-tractography"></a>
</h2>
<hr class="half-width">
<p>Probabilistic fiber tracking is a way of reconstructing the white
matter structural connectivity using diffusion MRI data. Much like
deterministic fiber tracking, the probabilistic approach follows the
trajectory of a possible pathway in a step-wise fashion and propagate
streamlines based on the local orientations reconstructed at each
voxel.</p>
<p>In probabilistic tracking, however, the tracking direction at each
point along the path is chosen at random from a distribution of possible
directions, and thus is no longer deterministic. The distribution at
each point is different and depends on the observed diffusion data at
that point. The distribution of tracking directions at each point can be
represented as a probability mass function (PMF) if the possible
tracking directions are restricted to a set of points distributed on a
sphere.</p>
<p>Like their deterministic counterparts, probabilistic tracking methods
start propagating streamlines from a <em>seed map</em>, which contains a
number of coordinates per voxel to initiate the procedure. The higher
the number of seeds per voxel (i.e. the seed density), the larger the
number of potentially recovered long-range connections. However, this
comes at the cost of a longer running time.</p>
<p>This episode builds on top of the results of the CSD local
orientation reconstruction method presented in a previous episode.</p>
<p>We will first get the necessary diffusion data, and compute the local
orientation information using the CSD method:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> nibabel <span class="im">as</span> nib</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">from</span> bids.layout <span class="im">import</span> BIDSLayout</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">from</span> dipy.core.gradients <span class="im">import</span> gradient_table</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="im">from</span> dipy.io.gradients <span class="im">import</span> read_bvals_bvecs</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>dwi_layout <span class="op">=</span> BIDSLayout(<span class="st">'../../data/ds000221/derivatives/uncorrected_topup_eddy/'</span>, validate<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>gradient_layout <span class="op">=</span> BIDSLayout(<span class="st">'../../data/ds000221/'</span>, validate<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>subj <span class="op">=</span> <span class="st">'010006'</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>dwi_fname <span class="op">=</span> dwi_layout.get(subject<span class="op">=</span>subj, suffix<span class="op">=</span><span class="st">'dwi'</span>, extension<span class="op">=</span><span class="st">'.nii.gz'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>bvec_fname <span class="op">=</span> dwi_layout.get(subject<span class="op">=</span>subj, extension<span class="op">=</span><span class="st">'.eddy_rotated_bvecs'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>bval_fname <span class="op">=</span> gradient_layout.get(subject<span class="op">=</span>subj, suffix<span class="op">=</span><span class="st">'dwi'</span>, extension<span class="op">=</span><span class="st">'.bval'</span>, return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>dwi_img <span class="op">=</span> nib.load(dwi)</span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>affine <span class="op">=</span> dwi_img.affine</span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a>gt_bvals, gt_bvecs <span class="op">=</span> read_bvals_bvecs(bval, bvec)</span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a>gtab <span class="op">=</span> gradient_table(gt_bvals, gt_bvecs)</span></code></pre>
</div>
<p>We will now create the seeding mask and the seeds using an estimate
of the white matter tissue based on the FA values obtained from the
diffusion tensor:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> dipy.reconst <span class="im">import</span> dti</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">from</span> dipy.segment.mask <span class="im">import</span> median_otsu</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="im">from</span> dipy.tracking <span class="im">import</span> utils</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>dwi_data <span class="op">=</span> dwi_img.get_fdata()</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>dwi_data, dwi_mask <span class="op">=</span> median_otsu(dwi_data, vol_idx<span class="op">=</span>[<span class="dv">0</span>], numpass<span class="op">=</span><span class="dv">1</span>)  <span class="co"># Specify the volume index to the b0 volumes</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>dti_model <span class="op">=</span> dti.TensorModel(gtab)</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>dti_fit <span class="op">=</span> dti_model.fit(dwi_data, mask<span class="op">=</span>dwi_mask)  <span class="co"># This step may take a while</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="co"># Create the seeding mask</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>fa_img <span class="op">=</span> dti_fit.fa</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>seed_mask <span class="op">=</span> fa_img.copy()</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>seed_mask[seed_mask <span class="op">&gt;=</span> <span class="fl">0.2</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>seed_mask[seed_mask <span class="op">&lt;</span> <span class="fl">0.2</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a><span class="co"># Create the seeds</span></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>seeds <span class="op">=</span> utils.seeds_from_mask(seed_mask, affine<span class="op">=</span>affine, density<span class="op">=</span><span class="dv">1</span>)</span></code></pre>
</div>
<p>We will now estimate the FRF and set the CSD model to feed the local
orientation information to the streamline propagation object:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">from</span> dipy.reconst.csdeconv <span class="im">import</span> (ConstrainedSphericalDeconvModel,</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>                                   auto_response_ssst)</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>response, ratio <span class="op">=</span> auto_response_ssst(gtab, dwi_data, roi_radii<span class="op">=</span><span class="dv">10</span>, fa_thr<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>sh_order <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>csd_model <span class="op">=</span> ConstrainedSphericalDeconvModel(gtab, response, sh_order<span class="op">=</span>sh_order)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>csd_fit <span class="op">=</span> csd_model.fit(dwi_data, mask<span class="op">=</span>seed_mask)</span></code></pre>
</div>
<p>Tracking methods are provided with a criterion to stop propagating
streamlines beyond non-white matter tissues. One way to do this is to
use the Generalized Fractional Anisotropy (GFA). Much like the
Fractional Anisotropy issued by the DTI model measures anisotropy, the
GFA uses samples of the ODF to quantify the anisotropy of tissues, and
hence, it provides an estimation of the underlying tissue type.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> ndimage  <span class="co"># To rotate image for visualization purposes</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="im">from</span> dipy.reconst.shm <span class="im">import</span> CsaOdfModel</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="im">from</span> dipy.tracking.stopping_criterion <span class="im">import</span> ThresholdStoppingCriterion</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>csa_model <span class="op">=</span> CsaOdfModel(gtab, sh_order<span class="op">=</span>sh_order)</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>gfa <span class="op">=</span> csa_model.fit(dwi_data, mask<span class="op">=</span>seed_mask).gfa</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>stopping_criterion <span class="op">=</span> ThresholdStoppingCriterion(gfa, <span class="fl">.2</span>)</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a><span class="co"># Create the directory to save the results</span></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>out_dir <span class="op">=</span> <span class="st">'../../data/ds000221/derivatives/dwi/tractography/sub-</span><span class="sc">%s</span><span class="st">/ses-01/dwi/'</span> <span class="op">%</span> subj</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(out_dir):</span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>    os.makedirs(out_dir)</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a><span class="co"># Save the GFA</span></span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a>gfa_img <span class="op">=</span> nib.Nifti1Image(gfa.astype(np.float32), affine)</span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>nib.save(gfa_img, os.path.join(out_dir, <span class="st">'gfa.nii.gz'</span>))</span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a><span class="co"># Plot the GFA</span></span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a>ax[<span class="dv">0</span>].imshow(ndimage.rotate(gfa[:, gfa.shape[<span class="dv">1</span>]<span class="op">//</span><span class="dv">2</span>, :], <span class="dv">90</span>, reshape<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a>ax[<span class="dv">1</span>].imshow(ndimage.rotate(gfa[gfa.shape[<span class="dv">0</span>]<span class="op">//</span><span class="dv">2</span>, :, :], <span class="dv">90</span>, reshape<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a>ax[<span class="dv">2</span>].imshow(ndimage.rotate(gfa[:, :, gfa.shape[<span class="op">-</span><span class="dv">1</span>]<span class="op">//</span><span class="dv">2</span>], <span class="dv">90</span>, reshape<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a>fig.savefig(os.path.join(out_dir, <span class="st">"gfa.png"</span>), dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb4-28"><a href="#cb4-28" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p>The GFA threshold stopping criterion value must be adjusted to the
data in order to avoid creating a mask that will exclude white matter
areas (which would result in streamlines being unable to propagate to
other white matter areas). Visually inspecting the GFA map might provide
with a sufficient guarantee about the goodness of the value.</p>
<p><img src="../fig/probabilistic_tractography/gfa.png" alt="GFA" class="figure"><br>
GFA</p>
<p>The Fiber Orientation Distribution (FOD) of the CSD model estimates
the distribution of small fiber bundles within each voxel. We can use
this distribution for probabilistic fiber tracking. One way to do this
is to represent the FOD using a discrete sphere. This discrete FOD can
be used by the <code>ProbabilisticDirectionGetter</code> as a PMF for
sampling tracking directions. We need to clip the FOD to use it as a PMF
because the latter cannot have negative values. Ideally, the FOD should
be strictly positive, but because of noise and/or model failures
sometimes it can have negative values.</p>
<p>The set of possible directions to choose to propagate a streamline is
restricted by a cone angle <span class="math inline">\(\theta\)</span>,
named <code>max_angle</code> in <code>DIPY</code>’s
<code>ProbabilisticDirectionGetter::from_pmf</code> method.</p>
<p>Another relevant parameter of the propagation is the step size, which
dictates how much the propagation will advance to the next point. Note
that it is a real number, since the tracking procedure operates in
physical coordinates.</p>
<p>Note that the <code>LocalTracking</code> class accepts a
<code>StoppingCriterion</code> class instance as its second argument,
and thus a different criterion can be used if the GFA criterion does not
fit into our framework, or if different data is available in our
workflow.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">from</span> dipy.direction <span class="im">import</span> ProbabilisticDirectionGetter</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="im">from</span> dipy.data <span class="im">import</span> small_sphere</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="im">from</span> dipy.io.stateful_tractogram <span class="im">import</span> Space, StatefulTractogram</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="im">from</span> dipy.io.streamline <span class="im">import</span> save_tractogram</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="im">from</span> dipy.tracking.local_tracking <span class="im">import</span> LocalTracking</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="im">from</span> dipy.tracking.streamline <span class="im">import</span> Streamlines</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>fod <span class="op">=</span> csd_fit.odf(small_sphere)</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>pmf <span class="op">=</span> fod.clip(<span class="bu">min</span><span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>prob_dg <span class="op">=</span> ProbabilisticDirectionGetter.from_pmf(pmf, max_angle<span class="op">=</span><span class="fl">30.</span>,</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>                                                sphere<span class="op">=</span>small_sphere)</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>streamline_generator <span class="op">=</span> LocalTracking(prob_dg, stopping_criterion, seeds,</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>                                     affine, step_size<span class="op">=</span><span class="fl">.5</span>)</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>streamlines <span class="op">=</span> Streamlines(streamline_generator)</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>sft <span class="op">=</span> StatefulTractogram(streamlines, dwi_img, Space.RASMM)</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a><span class="co"># Save the tractogram</span></span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>save_tractogram(sft, <span class="st">"tractogram_probabilistic_dg_pmf.trk"</span>)</span></code></pre>
</div>
<p>We will easily generate the anatomical views on the generated
tractogram using the <code>generate_anatomical_volume_figure</code>
helper function:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="im">from</span> fury <span class="im">import</span> actor, colormap</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="im">from</span> utils.visualization_utils <span class="im">import</span> generate_anatomical_volume_figure</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co"># Plot the tractogram</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="co"># Build the representation of the data</span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>streamlines_actor <span class="op">=</span> actor.line(streamlines, colormap.line_colors(streamlines))</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a><span class="co"># Generate the figure</span></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>fig <span class="op">=</span> generate_anatomical_volume_figure(streamlines_actor)</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>fig.savefig(os.path.join(out_dir, <span class="st">"tractogram_probabilistic_dg_pmf.png"</span>),</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a>            dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p><img src="../fig/probabilistic_tractography/tractogram_probabilistic_dg_pmf.png" alt="PMF direction getter-derived probabilistic tractogram" class="figure"><br>
Streamlines representing white matter using probabilistic direction
getter from PMF</p>
<p>One disadvantage of using a discrete PMF to represent possible
tracking directions is that it tends to take up a lot of RAM memory. The
size of the PMF, the FOD in this case, must be equal to the number of
possible tracking directions on the hemisphere, and every voxel has a
unique PMF. In this case the data is <code>(81, 106, 76)</code> and
<code>small_sphere</code> has 181 directions so the FOD is
<code>(81, 106, 76, 181)</code>. One way to avoid sampling the PMF and
holding it in memory is to build the direction getter directly from the
spherical harmonic (SH) representation of the FOD. By using this
approach, we can also use a larger sphere, like
<code>default_sphere</code> which has 362 directions on the hemisphere,
without having to worry about memory limitations.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">from</span> dipy.data <span class="im">import</span> default_sphere</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>prob_dg <span class="op">=</span> ProbabilisticDirectionGetter.from_shcoeff(csd_fit.shm_coeff,</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>                                                    max_angle<span class="op">=</span><span class="fl">30.</span>,</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>                                                    sphere<span class="op">=</span>default_sphere)</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>streamline_generator <span class="op">=</span> LocalTracking(prob_dg, stopping_criterion, seeds,</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>                                     affine, step_size<span class="op">=</span><span class="fl">.5</span>)</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>streamlines <span class="op">=</span> Streamlines(streamline_generator)</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>sft <span class="op">=</span> StatefulTractogram(streamlines, dwi_img, Space.RASMM)</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a><span class="co"># Save the tractogram</span></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>save_tractogram(sft, <span class="st">"tractogram_probabilistic_dg_sh.trk"</span>)</span></code></pre>
</div>
<p>We will visualize the tractogram using the three usual anatomical
views:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># Plot the tractogram</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co"># Build the representation of the data</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>streamlines_actor <span class="op">=</span> actor.line(streamlines, colormap.line_colors(streamlines))</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co"># Generate the figure</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>fig <span class="op">=</span> generate_anatomical_volume_figure(streamlines_actor)</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>fig.savefig(os.path.join(out_dir, <span class="st">"tractogram_probabilistic_dg_sh.png"</span>),</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>            dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p><img src="../fig/probabilistic_tractography/tractogram_probabilistic_dg_sh.png" alt="SH direction getter-derived probabilistic tractogram" class="figure"><br>
Streamlines representing white matter using probabilistic direction
getter from SH</p>
<p>Not all model fits have the <code>shm_coeff</code> attribute because
not all models use this basis to represent the data internally. However
we can fit the ODF of any model to the spherical harmonic basis using
the <code>peaks_from_model</code> function.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">from</span> dipy.direction <span class="im">import</span> peaks_from_model</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>peaks <span class="op">=</span> peaks_from_model(csd_model, dwi_data, default_sphere, <span class="fl">.5</span>, <span class="dv">25</span>,</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>                         mask<span class="op">=</span>seed_mask, return_sh<span class="op">=</span><span class="va">True</span>, parallel<span class="op">=</span><span class="va">True</span>)</span></code></pre>
</div>
<p>It is always good practice to (save and) visualize the peaks as a
check towards ensuring that the orientation information conforms to what
is expected as input to the tracking process.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># Save the peaks</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>nib.save(nib.Nifti1Image(reshape_peaks_for_visualization(peaks),</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>                         affine), os.path.join(out_dir, <span class="st">'peaks.nii.gz'</span>))</span></code></pre>
</div>
<p>As usual, we will use <code>FURY</code> to visualize the peaks:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="im">from</span> utils.visualization_utils <span class="im">import</span> generate_anatomical_slice_figure</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="co"># Visualize the peaks</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a><span class="co"># Build the representation of the data</span></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>peaks_actor <span class="op">=</span> actor.peak_slicer(peaks.peak_dirs, peaks.peak_values)</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a><span class="co"># Compute the slices to be shown</span></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>slices <span class="op">=</span> <span class="bu">tuple</span>(elem <span class="op">//</span> <span class="dv">2</span> <span class="cf">for</span> elem <span class="kw">in</span> dwi_data.shape[:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a><span class="co"># Generate the figure</span></span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>fig <span class="op">=</span> generate_anatomical_slice_figure(slices, peaks_actor)</span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>fig.savefig(os.path.join(out_dir, <span class="st">"peaks.png"</span>), dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p><img src="../fig/probabilistic_tractography/peaks.png" alt="CSD model peaks for tracking" class="figure"><br>
Peaks obtained from the CSD model for tracking purposes</p>
<p>We will now perform the tracking process using the local orientation
information provided by the peaks:</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>fod_coeff <span class="op">=</span> peaks.shm_coeff</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>prob_dg <span class="op">=</span> ProbabilisticDirectionGetter.from_shcoeff(fod_coeff, max_angle<span class="op">=</span><span class="fl">30.</span>,</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>                                                    sphere<span class="op">=</span>default_sphere)</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>streamline_generator <span class="op">=</span> LocalTracking(prob_dg, stopping_criterion, seeds,</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>                                     affine, step_size<span class="op">=</span><span class="fl">.5</span>)</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>streamlines <span class="op">=</span> Streamlines(streamline_generator)</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>sft <span class="op">=</span> StatefulTractogram(streamlines, dwi_img, Space.RASMM)</span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a><span class="co"># Save the tractogram</span></span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>save_tractogram(sft, <span class="st">"tractogram_probabilistic_dg_sh_pmf.trk"</span>)</span></code></pre>
</div>
<p>We will again visualize the tractogram using the three usual
anatomical views:</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># Plot the tractogram</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="co"># Build the representation of the data</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>streamlines_actor <span class="op">=</span> actor.line(streamlines, colormap.line_colors(streamlines))</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="co"># Generate the figure</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>fig <span class="op">=</span> generate_anatomical_volume_figure(streamlines_actor)</span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>fig.savefig(os.path.join(out_dir, <span class="st">"tractogram_probabilistic_dg_sh_pmf.png"</span>),</span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>            dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p><img src="../fig/probabilistic_tractography/tractogram_probabilistic_dg_sh_pmf.png" alt="PMF SH direction getter-derived probabilistic tractogram" class="figure"><br>
Streamlines representing white matter using probabilistic direction
getter from SH (peaks_from_model)</p>
<div id="tip-making-sure-your-tractogram-is-well-aligned-with-the-data" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="tip-making-sure-your-tractogram-is-well-aligned-with-the-data" class="callout-inner">
<h3 class="callout-title">Tip: Making sure your tractogram is well aligned with the data</h3>
<div class="callout-content">
<p>If for whatever reason the anatomical and diffusion images were not
correctly aligned, you may find that your tractogram is not well aligned
with the anatomical data. This may also happen derived from the
different formats in which a tractogram is saved/loaded, some
conventions specifying the origin at the voxel corner and other
specifying it at the center of the voxel. Visualizing the computed
features is always recommended. There are some tools that allow to
ensure that the matrices specifying the orientation and positioning of
the data should be correct.</p>
<p><code>MRtrix</code>’s <code>mrinfo</code> command can be used to
visualize the affine matrix of a <code>NIfTI</code> file as:</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="ex">mrinfo</span> dwi.nii.gz</span></code></pre>
</div>
<p>which would output something like:</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>************************************************
Image:               "/data/dwi.nii.gz"
************************************************
  Dimensions:        90 x 108 x 90 x 33
  Voxel size:        2 x 2 x 2 x 1
  Data strides:      [ -1 -2 3 4 ]
  Format:            NIfTI-1.1 (GZip compressed)
  Data type:         signed 16 bit integer (little endian)
  Intensity scaling: offset = 0, multiplier = 1
  Transform:                    1          -0           0      -178
                               -0           1           0      -214
                               -0          -0           1        -0</code></pre>
</div>
<p>Similarly, for your tractograms, you may use the command
<code>track_info</code> from <code>TrackVis</code>’
<code>Diffusion Toolkit</code> set of command-line tools:</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="ex">track_info</span> tractogram.trk</span></code></pre>
</div>
<p>which would output something like:</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>ID string:            TRACK
Version:              2
Dimension:            180 216 180
Voxel size:           1 1 1
Voxel order:          LPS
Voxel order original: LPS
Voxel to RAS matrix:
     -1.0000     0.0000     0.0000     0.5000
      0.0000    -1.0000     0.0000     0.5000
      0.0000     0.0000     1.0000    -0.5000
      0.0000     0.0000     0.0000     1.0000

Image Orientation:  1.0000/0.0000/0.0000/0.0000/1.0000/0.0000
Orientation patches:  none
Number of scalars:  0
Number of properties: 0
Number of tracks: 200433</code></pre>
</div>
<p>Note that, a <code>TRK</code> file contains orientational and
positional information. If you choose to store your tractograms using
the <code>TCK</code> format, this information will not be contained in
the file. To see the file header information you may use the
<code>MRtrix</code> <code>tckinfo</code> command:</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="ex">tckinfo</span> tractogram.tck</span></code></pre>
</div>
<p>which would output something like:</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>***********************************
 Tracks file: "/data/tractogram.tck"
   count:                0000200433
   dimensions:           (180, 216, 180)
   voxel_order:          LPS
   voxel_sizes:          (1.0, 1.0, 1.0)</code></pre>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Probabilistic tractography incorporates uncertainty to the tracking
process</li>
<li>Provides tractograms that explore more white matter axonal
fibers</li>
</ul>
</div>
</div>
</div>
<!-- Workshop-specific links -->
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-dMRI/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/carpentries-incubator/SDC-BIDS-dMRI/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries-incubator/SDC-BIDS-dMRI/" class="external-link">Source</a></p>
				<p><a href="https://github.com/carpentries-incubator/SDC-BIDS-dMRI/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:team@carpentries.org">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.10" class="external-link">sandpaper (0.16.10)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.7" class="external-link">pegboard (0.7.7)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.5" class="external-link">varnish (1.0.5)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://carpentries-incubator.github.io/SDC-BIDS-dMRI/instructor/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://carpentries-incubator.github.io/SDC-BIDS-dMRI/instructor/aio.html",
  "identifier": "https://carpentries-incubator.github.io/SDC-BIDS-dMRI/instructor/aio.html",
  "dateCreated": "2024-10-22",
  "dateModified": "2024-11-26",
  "datePublished": "2024-11-26"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo --><script>
          var _paq = window._paq = window._paq || [];
          /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
          _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
          _paq.push(["setDomains", ["*.lessons.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
          _paq.push(["setDoNotTrack", true]);
          _paq.push(["disableCookies"]);
          _paq.push(["trackPageView"]);
          _paq.push(["enableLinkTracking"]);
          (function() {
              var u="https://matomo.carpentries.org/";
              _paq.push(["setTrackerUrl", u+"matomo.php"]);
              _paq.push(["setSiteId", "1"]);
              var d=document, g=d.createElement("script"), s=d.getElementsByTagName("script")[0];
              g.async=true; g.src="https://matomo.carpentries.org/matomo.js"; s.parentNode.insertBefore(g,s);
          })();
        </script><!-- End Matomo Code -->
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

