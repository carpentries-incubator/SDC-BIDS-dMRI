{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Diffusion\n",
    "\n",
    "## Diffusion Weighted Imaging (DWI)\n",
    "\n",
    "Diffusion imaging probes the random, microscopic motion of water protons by employing MRI sequences which are sensitive to the geometry and environmental organization surrounding the water protons. This is a popular technique for studying the white matter of the brain. The diffusion within biological structures, such as the brain, are often restricted due to barriers (eg. cell membranes), resulting in a preferred direction of diffusion (anisotropy). A typical diffusion MRI scan will acquire multiple volumes that are sensitive to a particular diffusion direction and result in diffusion-weighted images (DWI). Diffusion that exhibits directionality in the same direction result in an attenuated signal. With further processing (to be discussed later in the lesson), the acquired images can provide measurements which are related to the microscopic changes and estimate white matter trajectories.\n",
    "\n",
    "_**ADD DWI FIGURE SHOWING DIRECTIONAL ATTENUATION**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b-values & b-vectors\n",
    "\n",
    "2 commonly seen values/files associated with diffusion datasets are `.bval` and `.bvec`. These files correspond to the b-values and b-vectors respectively. The b-value is the diffusion-sensitizing factor, and reflects the timing & strength of the gradients used to acquire the diffusion-weighted images. The b-vector corresponds to the direction of the diffusion sensitivity. Together these two files define the diffusion MRI measurement as a set of gradient directions and corresponding amplitudes. In a diffusion acquisition, volumes with no diffusion weighting (where the b-value is 0) are also acquired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For the rest of this tutorial, we will make use of a subset of publicly available dataset, ds000030, from [openneuro.org](https://openneuro.org/datasets/ds000030) The dataset is structured according to the Brain Imaging Data Structure ([BIDS](https://bids-specification.readthedocs.io/en/etable/)). \n",
    "\n",
    "Below is a tree diagram showing the folder structure of a single MR session within ds000030. This was obtained by using the bash command `tree`.  \n",
    "`!tree ../data/ds000030`\n",
    "\n",
    "```\n",
    "ds000030\n",
    "├── CHANGES\n",
    "├── code\n",
    "├── dataset_description.json\n",
    "├── README\n",
    "└── sub-10788/\n",
    "    ├── anat\n",
    "    │   ├── sub-10788_T1w.json\n",
    "    │   └── sub-10788_T1w.nii.gz\n",
    "    └── dwi\n",
    "        ├── sub-10788_dwi.bval\n",
    "        │── sub-10788_dwi.bvec\n",
    "        │── sub-10788_dwi.json\n",
    "        └── sub-10788_dwi.nii.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying a BIDS Dataset\n",
    "\n",
    "[`pybids`](https://bids-standard.github.io/pybids/) is a Python API for querying, summarizing and manipulating the BIDS folder structure. We will make use of `pybids` to query the necessary files. \n",
    "\n",
    "Lets first pull the metadata from its associated JSON file using the `get_metadata()` function for the first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids.layout import BIDSLayout\n",
    "\n",
    "layout = BIDSLayout(\"../data/ds000030\", validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AccelerationFactorPE': 1,\n",
       " 'AcquisitionMatrix': '96/0/0/96',\n",
       " 'DeviceSerialNumber': '35343',\n",
       " 'EPIFactor': 128,\n",
       " 'EchoTime': 0.0926,\n",
       " 'EchoTrainLength': 1,\n",
       " 'EffectiveEchoSpacing': 0.000689983,\n",
       " 'FlipAngle': 90,\n",
       " 'ImageType': 'ORIGINAL/PRIMARY/M/ND/MOSAIC',\n",
       " 'ImagingFrequency': 123227595,\n",
       " 'InPlanePhaseEncodingDirection': 'COL',\n",
       " 'MRAcquisitionType': '2D',\n",
       " 'MagneticFieldStrength': 3,\n",
       " 'ManufacturerModelName': 'TrioTim',\n",
       " 'NumberOfAverages': 1,\n",
       " 'NumberOfPhaseEncodingSteps': 72,\n",
       " 'PatientPosition': 'HFS',\n",
       " 'PercentPhaseFieldOfView': 100,\n",
       " 'PercentSampling': 100,\n",
       " 'PhaseEncodingDirection': 'j-',\n",
       " 'PixelBandwidth': 2265,\n",
       " 'ProtocolName': 'DTI 64dir',\n",
       " 'ReceiveCoilName': 'HeadMatrix',\n",
       " 'RepetitionTime': 8.4,\n",
       " 'ScanOptions': 'PFP/FS',\n",
       " 'ScanningSequence': 'EP',\n",
       " 'SequenceName': '*ep_b1000#10',\n",
       " 'SequenceVariant': 'SK/SP',\n",
       " 'SliceTiming': [4.2175,\n",
       "  0,\n",
       "  4.3575,\n",
       "  0.14,\n",
       "  4.4975,\n",
       "  0.28,\n",
       "  4.6375,\n",
       "  0.4225,\n",
       "  4.7775,\n",
       "  0.5625,\n",
       "  4.92,\n",
       "  0.7025,\n",
       "  5.06,\n",
       "  0.8425,\n",
       "  5.2,\n",
       "  0.985,\n",
       "  5.34,\n",
       "  1.125,\n",
       "  5.4825,\n",
       "  1.265,\n",
       "  5.6225,\n",
       "  1.405,\n",
       "  5.7625,\n",
       "  1.545,\n",
       "  5.9025,\n",
       "  1.6875,\n",
       "  6.0425,\n",
       "  1.8275,\n",
       "  6.185,\n",
       "  1.9675,\n",
       "  6.325,\n",
       "  2.1075,\n",
       "  6.465,\n",
       "  2.2475,\n",
       "  6.605,\n",
       "  2.39,\n",
       "  6.7475,\n",
       "  2.53,\n",
       "  6.8875,\n",
       "  2.67,\n",
       "  7.0275,\n",
       "  2.81,\n",
       "  7.1675,\n",
       "  2.9525,\n",
       "  7.3075,\n",
       "  3.0925,\n",
       "  7.45,\n",
       "  3.2325,\n",
       "  7.59,\n",
       "  3.3725,\n",
       "  7.73,\n",
       "  3.5125,\n",
       "  7.87,\n",
       "  3.655,\n",
       "  8.0125,\n",
       "  3.795,\n",
       "  8.1525,\n",
       "  3.935,\n",
       "  8.2925,\n",
       "  4.075],\n",
       " 'SoftwareVersions': 'syngo MR B15',\n",
       " 'TotalReadoutTime': 0.088317824,\n",
       " 'TotalScanTimeSec': 556,\n",
       " 'TransmitCoilName': 'Body',\n",
       " 'VariableFlipAngleFlag': 'N'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwi = layout.get(subject='10788', suffix='dwi', extension='nii.gz', return_type='file')[0]\n",
    "layout.get_metadata(dwi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [`dipy`](http://dipy.org)\n",
    "\n",
    "For this lesson, we will use the `Dipy` (Diffusion Imaging in Python) package for processing and analysing diffusion MRI.\n",
    "\n",
    "### Why `dipy`? \n",
    "\n",
    "- Fully free and open source\n",
    "- Implemented in Python. Easy to understand, and easy to use.\n",
    "- Implementations of many state-of-the art algorithms\n",
    "- High performance. Many algorithms implemented in [`cython`](http://cython.org/)\n",
    "\n",
    "### Installing `dipy`\n",
    "\n",
    "The easiest way to install `Dipy` is to use `pip`! Additionally, `Dipy` makes use of the FURY library for visualization. We will also install this using `pip`!\n",
    "\n",
    "We can install it by entering the following in a terminal `pip install dipy`. We will do so using Jupyter Magic in the following cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dipy in /home/tkai/.venv/dti_venv/lib/python3.6/site-packages (1.0.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/tkai/.venv/dti_venv/lib/python3.6/site-packages (from dipy) (1.3.1)\n",
      "Requirement already satisfied: h5py>=2.4.0 in /home/tkai/.venv/dti_venv/lib/python3.6/site-packages (from dipy) (2.10.0)\n",
      "Requirement already satisfied: nibabel>=2.4.0 in /home/tkai/.venv/dti_venv/lib/python3.6/site-packages (from dipy) (2.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/tkai/.venv/dti_venv/lib/python3.6/site-packages (from scipy>=1.0->dipy) (1.16.4)\n",
      "Requirement already satisfied: six in /home/tkai/.venv/dti_venv/lib/python3.6/site-packages (from h5py>=2.4.0->dipy) (1.12.0)\n",
      "Requirement already satisfied: fury in /home/tkai/.venv/dti_venv/lib/python3.6/site-packages (0.3.0)\n",
      "Requirement already satisfied: vtk>=8.1.0 in /home/tkai/.venv/dti_venv/lib/python3.6/site-packages (from fury) (8.1.2)\n",
      "Requirement already satisfied: scipy>=0.9 in /home/tkai/.venv/dti_venv/lib/python3.6/site-packages (from fury) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /home/tkai/.venv/dti_venv/lib/python3.6/site-packages (from fury) (1.16.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install dipy\n",
    "! pip install fury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a measurement: `GradientTable`\n",
    "\n",
    "`Dipy` has a built-in function that allows us to read in `bval` and `bvec` files named `read_bvals_bvecs` under the `dipy.io.gradients` module. Let's first grab the path to our gradient directions and amplitude files and load them into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bvec = layout.get(subject='10788', suffix='dwi', extension='bvec', return_type='file')[0]\n",
    "bval = layout.get(subject='10788', suffix='dwi', extension='bval', return_type='file')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table\n",
    "\n",
    "bvals, bvecs = read_bvals_bvecs(bval, bvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "There is a also simple `GradientTable` object implemented in the `dipy.core.gradients` module. The input to the `GradientTable` should be our the values for our gradient directions and amplitudes we just read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtab = gradient_table(bvals, bvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need this gradient table later on to process our data and generate diffusion tensor images (DTI)! \n",
    "\n",
    "There is also a built in function for gradient tables, `b0s_mask` that can be used to separate difussion weighted measurements from non-diffusion weighted measurements (b=0s/mm^2). Try to extract the vector corresponding to non-diffusion weighted measurement in the following cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtab.bvecs[gtab.b0s_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next few notebooks, we will talk more about preprocessing the diffusion weighted images and reconstructing the Tensor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dti_venv",
   "language": "python",
   "name": "dti_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
