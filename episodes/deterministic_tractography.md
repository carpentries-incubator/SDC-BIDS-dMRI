---
title: "Deterministic tractography"
teaching: 30
exercises: 0
questions:
- "What computations does a deterministic tractography require?"
- "How can we visualize the streamlines generated by a tractography method?"
objectives:
- "Be able to perform deterministic tracking on diffusion MRI data"
- "Familiarize with the data entities of a tractogram"
keypoints:
- "Deterministic tractography methods perform tracking in a predictable way"
---

## Deterministic tractography

Deterministic tractography algorithms perform tracking of streamlines by
following a predictable path, such as following the primary diffusion direction
($\lambda_1$).

In order to demonstrate how to perform deterministic tracking on a diffusion MRI
dataset, we will quickly repeat the steps from the previous notebook and compute
the diffusion tensor. We will additionally extract the `affine` data from the
diffusion image, which we will need later on!

~~~
from bids.layout import BIDSLayout
from dipy.io.gradients import read_bvals_bvecs
from dipy.core.gradients import gradient_table
from nilearn import image as img
import nibabel as nib

layout = BIDSLayout("../data/ds000221/derivatives", validate=False)

subj = '010006'

dwi = layout.get(subject='010006', suffix='preproc', extension='nii.gz', return_type='file')[0]
bval = layout.get(subject='010006', suffix='preproc', extension='bval', return_type='file')[0]
bvec = layout.get(subject='010006', suffix='preproc', extension='bvec', return_type='file')[0]

dwi_img = img.load_img(dwi)
affine = dwi_img.affine

gt_bvals, gt_bvecs = read_bvals_bvecs(bval, bvec)
gtab = gradient_table(gt_bvals, gt_bvecs)

import dipy.reconst.dti as dti
from dipy.segment.mask import median_otsu

dwi_data = dwi_img.get_data()
dwi_data, dwi_mask = median_otsu(dwi_data, vol_idx=[0], numpass=1)  # Specify the volume index to the b0 volumes

dti_model = dti.TensorModel(gtab)
dti_fit = dti_model.fit(dwi_data, mask=dwi_mask)  # This step may take a while
~~~
{: .language-python}

We will perform tracking using a deterministic algorithm on tensor fields via
`EuDX` [(Garyfallidis _et al._, 2012)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3518823/).
`EuDX` makes use of the primary direction of the diffusion tensor to propagate
streamlines from voxel to voxel and a stopping criteria from the fractional
anisotropy (FA). We will get the FA map and eigenvectors from our tensor
fitting.

~~~
fa_img = dti_fit.fa
evecs_img = dti_fit.evecs
~~~
{: .language-python}

In the background of the image, the fitting may not be accurate as all of the
measured signal is primarily noise and it is possible that values of NaNs (not
a number) may be found in the FA map. We can remove these using `numpy` to
find and set these voxels to 0.

~~~
import numpy as np

fa_img[np.isnan(fa_img)] = 0
~~~
{: .language-python}

One of the inputs of `EuDX` is the discretized voxel directions on a unit
sphere. Therefore, it is necessary to discretize the eigenvectors before
providing them to `EuDX`. We will use an evenly distributed sphere of 362 points
using the `get_sphere` function.

~~~
from dipy.data import get_sphere

sphere = get_sphere('symmetric362')
~~~
{: .language-python}

We will determine the indices representing the discretized directions of the
peaks by providing as input, our tensor model, the diffusion data, the sphere,
and a mask to apply the processing to. Additionally, we will set the minimum
angle between directions, the maximum number of peaks to return (1 for the
tensor model), and the relative peak threshold (returning peaks greater than
this value).

> Note
> This step may take a while to run.
{: .callout}

~~~
from dipy.direction import peaks_from_model

peak_indices = peaks_from_model(model=dti_model, data=dwi_data, sphere=sphere, relative_peak_threshold=.2, min_separation_angle=25, mask=dwi_mask, npeaks=2)
~~~
{: .language-python}

Additionally, we will apply a stopping criterion for our tracking based on the
FA map. That is, we will stop our tracking when we reach a voxel where FA is
below 0.2.

~~~
from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion

stopping_criterion = ThresholdStoppingCriterion(fa_img, .2)
~~~
{: .language-python}

We will also need to specify where to "seed" (begin) the fiber tracking.
Generally, the seeds chosen will depend on the pathways one is interested in
modelling. In this example, we will create a seed mask from the FA map
thresholding above our stopping criterion.

~~~
from dipy.tracking import utils

seed_mask = fa_img.copy()
seed_mask[seed_mask>=0.2] = 1
seed_mask[seed_mask<0.2] = 0

seeds = utils.seeds_from_mask(seed_mask, affine=affine, density=1)
~~~
{: .language-python}

Now, we can apply the tracking algorithm!

As mentioned previously, `EuDX` is the fiber tracking algorithm that we will be
using. The most important parameters to include are the indices representing the
discretized directions of the peaks (`peak_indices`), the stopping criterion,
the seeds, the affine transformation, and the step sizes to take when tracking!

~~~
from dipy.tracking.local_tracking import LocalTracking
from dipy.tracking.streamline import Streamlines

# Initialize local tracking - computation happens in the next step.
streamlines_generator = LocalTracking(peak_indices, stopping_criterion, seeds, affine=affine, step_size=.5)

# Generate streamlines object
streamlines = Streamlines(streamlines_generator)
~~~
{: .language-python}

We just created a deterministic set of streamlines using the `EuDX` algorithm
mapping the human connectome (tractography). We can save the streamlines as a
[TrackVis] file so it can be loaded into other software for visualization or
further analysis. To do so, we need to save the tractogram state using
`StatefulTractogram` and `save_trk` to save the file. Note that we will have to
specify the space to save the tractogram in.

~~~
from dipy.io.stateful_tractogram import Space, StatefulTractogram
from dipy.io.streamline import save_trk

sft = StatefulTractogram(streamlines, dwi_img, Space.RASMM)
save_trk(sft, "tractogram_EuDX.trk")
~~~
{: .language-python}

We can then generate the streamlines 3D scene using the `fury` python package,
and visualize the scene's contents with `matplotlib`.

~~~
from dipy.io.streamline import load_trk
from dipy.viz import window, actor, colormap

sft = load_trk('tractogram_EuDX.trk', 'same')
sft.to_vox()
streamlines = sft.streamlines

from dipy.viz import window, actor, colormap

# Prepare display objects
# streamlines_actor = actor.line(streamlines, colormap.line_colors(streamlines))
streamlines_actor = actor.line(streamlines)

# Create the directory to save the results
out_dir = '../../data/ds000221/derivatives/dwi/tractography/sub-%s/ses-01/dwi/' % subj

if not os.path.exists(out_dir):
    os.makedirs(out_dir)

# Create 3D display
scene = window.Scene()

det_tractogram_eudx_scene_arr = window.snapshot(
    scene,
    fname=os.path.join(out_dir, 'tractogram_EuDX.png'),
    size=(800, 800), offscreen=True)

import matplotlib.pyplot as plt
%matplotlib inline

# Show the image
fig, axes = plt.subplots()
axes.imshow(det_tractogram_eudx_scene_arr, origin="lower")
axes.axis("off")
plt.show()
~~~
{: .language-python}


{% include links.md %}
