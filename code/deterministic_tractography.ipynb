{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic tractography\n",
    "\n",
    "Deterministic tractography algorithms perform tracking of streamlines by following a predictable path, such as following the primary diffusion direction.\n",
    "\n",
    "In order to demonstrate how to perform deterministic tracking on a diffusion MRI dataset, we will build from the preprocessing presented in a previous episode and compute the diffusion tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "import bids\n",
    "from bids.layout import BIDSLayout\n",
    "\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table\n",
    "\n",
    "\n",
    "bids.config.set_option('extension_initial_dot', True)\n",
    "\n",
    "dwi_layout = BIDSLayout(\n",
    "    \"../data/ds000221/derivatives/uncorrected_topup_eddy\", validate=False)\n",
    "gradient_layout = BIDSLayout(\"../data/ds000221/\", validate=False)\n",
    "\n",
    "subj = '010006'\n",
    "\n",
    "dwi_fname = dwi_layout.get(subject=subj, suffix='dwi',\n",
    "                           extension='nii.gz', return_type='file')[0]\n",
    "bvec_fname = dwi_layout.get(\n",
    "    subject=subj, extension='eddy_rotated_bvecs', return_type='file')[0]\n",
    "bval_fname = gradient_layout.get(\n",
    "    subject=subj, suffix='dwi', extension='bval', return_type='file')[0]\n",
    "\n",
    "dwi_img = nib.load(dwi_fname)\n",
    "affine = dwi_img.affine\n",
    "\n",
    "bvals, bvecs = read_bvals_bvecs(bval_fname, bvec_fname)\n",
    "gtab = gradient_table(bvals, bvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a mask and constrain the fitting within the mask.\n",
    "\n",
    "_Note that many steps in the streamline propagation procedure are\n",
    "computationally intensive, and thus may take a while to complete._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dipy.reconst.dti as dti\n",
    "from dipy.segment.mask import median_otsu\n",
    "\n",
    "dwi_data = dwi_img.get_fdata()\n",
    "# Specify the volume index to the b0 volumes\n",
    "dwi_data, dwi_mask = median_otsu(dwi_data, vol_idx=[0], numpass=1)\n",
    "\n",
    "dti_model = dti.TensorModel(gtab)\n",
    "dti_fit = dti_model.fit(dwi_data, mask=dwi_mask)  # This step may take a while"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform tracking using a deterministic algorithm on tensor fields via `EuDX` [(Garyfallidis _et al._, 2012)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3518823/). `EuDX` makes use of the primary direction of the diffusion tensor to propagate streamlines from voxel to voxel and a stopping criteria from the fractional anisotropy (FA).\n",
    "\n",
    "We will first get the FA map and eigenvectors from our tensor fitting. In the background of the FA map, the fitting may not be accurate as all of the measured signal is primarily noise and it is possible that values of NaNs (not a number) may be found in the FA map. We can remove these using `numpy` to find and set these voxels to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory to save the results\n",
    "\n",
    "from scipy import ndimage  # To rotate image for visualization purposes\n",
    "import matplotlib.pyplot as plt\n",
    "out_dir = f\"../data/ds000221/derivatives/dwi/tractography/sub-{subj}/ses-01/dwi/\"\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "fa_img = dti_fit.fa\n",
    "evecs_img = dti_fit.evecs\n",
    "\n",
    "fa_img[np.isnan(fa_img)] = 0\n",
    "\n",
    "# Save the FA\n",
    "fa_nii = nib.Nifti1Image(fa_img.astype(np.float32), affine)\n",
    "nib.save(fa_nii, os.path.join(out_dir, 'fa.nii.gz'))\n",
    "\n",
    "# Plot the FA\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 10))\n",
    "ax[0].imshow(ndimage.rotate(\n",
    "    fa_img[:, fa_img.shape[1]//2, :], 90, reshape=False))\n",
    "ax[1].imshow(ndimage.rotate(\n",
    "    fa_img[fa_img.shape[0]//2, :, :], 90, reshape=False))\n",
    "ax[2].imshow(ndimage.rotate(\n",
    "    fa_img[:, :, fa_img.shape[-1]//2], 90, reshape=False))\n",
    "fig.savefig(os.path.join(out_dir, \"fa.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the inputs of `EuDX` is the discretized voxel directions on a unit sphere. Therefore, it is necessary to discretize the eigenvectors before providing them to `EuDX`. We will use an evenly distributed sphere of 362 points using the `get_sphere` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.data import get_sphere\n",
    "\n",
    "sphere = get_sphere('symmetric362')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will determine the indices representing the discretized directions of the peaks by providing as input, our tensor model, the diffusion data, the sphere, and a mask to apply the processing to. Additionally, we will set the minimum angle between directions, the maximum number of peaks to return (1 for the tensor model), and the relative peak threshold (returning peaks greater than this value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.direction import peaks_from_model\n",
    "\n",
    "peak_indices = peaks_from_model(model=dti_model, data=dwi_data, sphere=sphere,\n",
    "                                relative_peak_threshold=.2, min_separation_angle=25, mask=dwi_mask, npeaks=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we will apply a stopping criterion for our tracking based on the FA map. That is, we will stop our tracking when we reach a voxel where FA is below 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion\n",
    "\n",
    "stopping_criterion = ThresholdStoppingCriterion(fa_img, .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need to specify where to \"seed\" (begin) the fiber tracking. Generally, the seeds chosen will depend on the pathways one is interested in modelling. In this example, we will create a seed mask from the FA map thresholding above our stopping criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking import utils\n",
    "\n",
    "seed_mask = fa_img.copy()\n",
    "seed_mask[seed_mask >= 0.2] = 1\n",
    "seed_mask[seed_mask < 0.2] = 0\n",
    "\n",
    "seeds = utils.seeds_from_mask(seed_mask, affine=affine, density=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can apply the tracking algorithm!\n",
    "\n",
    "As mentioned previously, `EuDX` is the fiber tracking algorithm that we will be using. The most important parameters to include are the indices representing the discretized directions of the peaks (`peak_indices`), the stopping criterion, the seeds, the affine transformation, and the step sizes to take when tracking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.local_tracking import LocalTracking\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "\n",
    "# Initialize local tracking - computation happens in the next step.\n",
    "streamlines_generator = LocalTracking(\n",
    "    peak_indices, stopping_criterion, seeds, affine=affine, step_size=.5)\n",
    "\n",
    "# Generate streamlines object\n",
    "streamlines = Streamlines(streamlines_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just created a deterministic set of streamlines using the `EuDX` algorithm mapping the human brain connectome (tractography). We can save the streamlines as a `Trackvis` file so it can be loaded into other software for visualization or further analysis. To do so, we need to save the tractogram state using `StatefulTractogram` and `save_tractogram` to save the file. Note that we will have to specify the space to save the tractogram in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.io.stateful_tractogram import Space, StatefulTractogram\n",
    "from dipy.io.streamline import save_tractogram\n",
    "\n",
    "sft = StatefulTractogram(streamlines, dwi_img, Space.RASMM)\n",
    "\n",
    "# Save the tractogram\n",
    "save_tractogram(sft, os.path.join(\n",
    "    out_dir, \"tractogram_deterministic_EuDX.trk\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then generate the streamlines 3D scene using the `FURY` python package, and visualize the scene's contents with `Matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualization_utils import generate_anatomical_volume_figure\n",
    "from fury import actor, colormap\n",
    "\n",
    "# Plot the tractogram\n",
    "\n",
    "# Build the representation of the data\n",
    "streamlines_actor = actor.line(streamlines, colormap.line_colors(streamlines))\n",
    "\n",
    "# Generate the figure\n",
    "fig = generate_anatomical_volume_figure(streamlines_actor)\n",
    "\n",
    "fig.savefig(os.path.join(out_dir, \"tractogram_deterministic_EuDX.png\"),\n",
    "            dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Exercise 1\n",
    "\n",
    "In this episode, we applied a threshold stopping criteria\n",
    "to stop tracking when we reach a voxel where FA is below 0.2.\n",
    "There are also other stopping criteria available. We encourage\n",
    "you to read the `DIPY` documentation about the others. For this\n",
    "exercise, repeat the tractography, but apply a binary stopping\n",
    "criteria (`BinaryStoppingCriterion`) using the seed mask.\n",
    "Visualize the tractogram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "from bids.layout import BIDSLayout\n",
    "\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.data import get_sphere\n",
    "from dipy.direction import peaks_from_model\n",
    "import dipy.reconst.dti as dti\n",
    "from dipy.segment.mask import median_otsu\n",
    "from dipy.tracking import utils\n",
    "from dipy.tracking.stopping_criterion import BinaryStoppingCriterion\n",
    "from dipy.tracking.local_tracking import LocalTracking\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from fury import actor, colormap\n",
    "\n",
    "dwi_layout = BIDSLayout(\n",
    "    \"../data/ds000221/derivatives/uncorrected_topup_eddy\", validate=False)\n",
    "gradient_layout = BIDSLayout(\"../data/ds000221/\", validate=False)\n",
    "\n",
    "# Get subject data\n",
    "subj = '010006'\n",
    "dwi_fname = dwi_layout.get(subject=subj, suffix='dwi',\n",
    "                           extension='nii.gz', return_type='file')[0]\n",
    "bvec_fname = dwi_layout.get(\n",
    "    subject=subj, extension='eddy_rotated_bvecs', return_type='file')[0]\n",
    "bval_fname = gradient_layout.get(\n",
    "    subject=subj, suffix='dwi', extension='bval', return_type='file')[0]\n",
    "\n",
    "dwi_img = nib.load(dwi_fname)\n",
    "affine = dwi_img.affine\n",
    "\n",
    "bvals, bvecs = read_bvals_bvecs(bval_fname, bvec_fname)\n",
    "gtab = gradient_table(bvals, bvecs)\n",
    "\n",
    "dwi_data = dwi_img.get_fdata()\n",
    "# Specify the volume index to the b0 volumes\n",
    "dwi_data, dwi_mask = median_otsu(dwi_data, vol_idx=[0], numpass=1)\n",
    "\n",
    "# Fit tensor and compute FA map\n",
    "dti_model = dti.TensorModel(gtab)\n",
    "dti_fit = dti_model.fit(dwi_data, mask=dwi_mask)\n",
    "fa_img = dti_fit.fa\n",
    "evecs_img = dti_fit.evecs\n",
    "\n",
    "sphere = get_sphere('symmetric362')\n",
    "peak_indices = peaks_from_model(model=dti_model, data=dwi_data, sphere=sphere,\n",
    "                                relative_peak_threshold=.2, min_separation_angle=25, mask=dwi_mask, npeaks=2)\n",
    "\n",
    "# Create a binary seed mask\n",
    "seed_mask = fa_img.copy()\n",
    "seed_mask[seed_mask >= 0.2] = 1\n",
    "seed_mask[seed_mask < 0.2] = 0\n",
    "\n",
    "seeds = utils.seeds_from_mask(seed_mask, affine=affine, density=1)\n",
    "\n",
    "# Set stopping criteria\n",
    "stopping_criterion = BinaryStoppingCriterion(seed_mask == 1)\n",
    "\n",
    "# Perform tracking\n",
    "streamlines_generator = LocalTracking(\n",
    "    peak_indices, stopping_criterion, seeds, affine=affine, step_size=.5)\n",
    "streamlines = Streamlines(streamlines_generator)\n",
    "\n",
    "# Plot the tractogram\n",
    "# Build the representation of the data\n",
    "streamlines_actor = actor.line(streamlines, colormap.line_colors(streamlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from utils.visualization_utils import generate_anatomical_volume_figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the figure\n",
    "fig = generate_anatomical_volume_figure(streamlines_actor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –––––––––––––--––– #\n",
    "# –––– Solution –––– #\n",
    "# ––––––––––––––--–– #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Exercise 2\n",
    "\n",
    "As an additional challenge, set the\n",
    "color of the streamlines to display the values of the\n",
    "FA map and change the opacity to `0.05`. You may need to transform the streamlines from world coordinates to the subject's native space using `transform_streamlines` from `dipy.tracking.streamline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fury import actor\n",
    "\n",
    "from dipy.tracking.streamline import transform_streamlines\n",
    "\n",
    "streamlines_native = transform_streamlines(streamlines, np.linalg.inv(affine))\n",
    "streamlines_actor = actor.line(streamlines_native, fa_img, opacity=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from utils.visualization_utils import generate_anatomical_volume_figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = generate_anatomical_volume_figure(streamlines_actor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –––––––––––––--––– #\n",
    "# –––– Solution –––– #\n",
    "# ––––––––––––––--–– #\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
