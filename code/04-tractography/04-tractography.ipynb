{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic tractography\n",
    "\n",
    "Deterministic tractography algorithms perform tracking of streamlines by following a predictable path, such as following the primary diffusion direction ($\\lambda_1$).\n",
    "\n",
    "In order to demonstrate how to perform deterministic tracking on a diffusion MRI dataset, we will quickly repeat the steps from the previous notebook and compute the diffusion tensor. We will additionally extract the `affine` data from the diffusion image, which we will need later on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "from bids.layout import BIDSLayout\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table\n",
    "from nilearn import image as img\n",
    "import nibabel as nib\n",
    "\n",
    "layout = BIDSLayout(\"../../data/ds000221/derivatives\", validate=False)\n",
    "\n",
    "subj = '010006'\n",
    "\n",
    "dwi = layout.get(subject=subj, suffix='preproc', extension='nii.gz', return_type='file')[0]\n",
    "bval = layout.get(subject=subj suffix='preproc', extension='bval', return_type='file')[0]\n",
    "bvec = layout.get(subject=subj suffix='preproc', extension='bvec', return_type='file')[0]\n",
    "\n",
    "dwi_img = img.load_img(dwi)\n",
    "affine = dwi_img.affine\n",
    "\n",
    "gt_bvals, gt_bvecs = read_bvals_bvecs(bval, bvec)\n",
    "gtab = gradient_table(gt_bvals, gt_bvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "import dipy.reconst.dti as dti\n",
    "from dipy.segment.mask import median_otsu\n",
    "\n",
    "dwi_data = dwi_img.get_data()\n",
    "dwi_data, dwi_mask = median_otsu(dwi_data, vol_idx=[0], numpass=1)  # Specify the volume index to the b0 volumes\n",
    "\n",
    "dti_model = dti.TensorModel(gtab)\n",
    "dti_fit = dti_model.fit(dwi_data, mask=dwi_mask)  # This step may take a while"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform tracking using a deterministic algorithm on tensor fields via `EuDX` [(Garyfallidis _et al._, 2012)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3518823/). `EuDX` makes use of the primary direction of the diffusion tensor to propagate streamlines from voxel to voxel and a stopping criteria from the fractional anisotropy (FA). We will get the FA map and eigenvectors from our tensor fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_img = dti_fit.fa\n",
    "evecs_img = dti_fit.evecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the background of the image, the fitting may not be accurate as all of the measured signal is primarily noise and it is possible that values of NaNs (not a number) may be found in the FA map. We can remove these using `numpy` to find and set these voxels to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fa_img[np.isnan(fa_img)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the inputs of `EuDX` is the discretized voxel directions on a unit sphere. Therefore, it is necessary to discretize the eigenvectors before providing them to `EuDX`. We will use an evenly distributed sphere of 362 points using the `get_sphere` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.data import get_sphere\n",
    "\n",
    "sphere = get_sphere('symmetric362')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will determine the indices representing the discretized directions of the peaks by providing as input, our tensor model, the diffusion data, the sphere, and a mask to apply the processing to. Additionally, we will set the minimum angle between directions, the maximum number of peaks to return (1 for the tensor model), and the relative peak threshold (returning peaks greater than this value).\n",
    "\n",
    "_Note: This step may take a while to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.direction import peaks_from_model\n",
    "\n",
    "peak_indices = peaks_from_model(model=dti_model, data=dwi_data, sphere=sphere, relative_peak_threshold=.2, min_separation_angle=25, mask=dwi_mask, npeaks=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we will apply a stopping criterion for our tracking based on the FA map. That is, we will stop our tracking when we reach a voxel where FA is below 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion\n",
    "\n",
    "stopping_criterion = ThresholdStoppingCriterion(fa_img, .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need to specify where to \"seed\" (begin) the fiber tracking. Generally, the seeds chosen will depend on the pathways one is interested in modelling. In this example, we will create a seed mask from the FA map thresholding above our stopping criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking import utils\n",
    "\n",
    "seed_mask = fa_img.copy()\n",
    "seed_mask[seed_mask>=0.2] = 1\n",
    "seed_mask[seed_mask<0.2] = 0\n",
    "\n",
    "seeds = utils.seeds_from_mask(seed_mask, affine=affine, density=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can apply the tracking algorithm! \n",
    "\n",
    "As mentioned previously, `EuDX` is the fiber tracking algorithm that we will be using. The most important parameters to include are the indices representing the discretized directions of the peaks (`peak_indices`), the stopping criterion, the seeds, the affine transformation, and the step sizes to take when tracking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.local_tracking import LocalTracking\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "\n",
    "# Initialize local tracking - computation happens in the next step.\n",
    "streamlines_generator = LocalTracking(peak_indices, stopping_criterion, seeds, affine=affine, step_size=.5)\n",
    "\n",
    "# Generate streamlines object\n",
    "streamlines = Streamlines(streamlines_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just created a deterministic set of streamlines using the `EuDX` algorithm mapping the human connectome (tractography). We can save the streamlines as a Trackvis file so it can be loaded into other software for visualization or further analysis. To do so, we need to save the tractogram state using `StatefulTractogram` and `save_trk` to save the file. Note that we will have to specify the space to save the tractogram in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.io.stateful_tractogram import Space, StatefulTractogram\n",
    "from dipy.io.streamline import save_trk\n",
    "\n",
    "sft = StatefulTractogram(streamlines, dwi_img, Space.RASMM)\n",
    "save_trk(sft, \"tractogram_EuDX.trk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then generate the streamlines 3D scene using the `fury` python package,\n"
    "and visualize the scene's contents with `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.io.streamline import load_tractogram\n",
    "from dipy.io.streamline import load_trk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sft = load_tractogram('tractogram_EuDX.trk', 'same')\n",
    "sft = load_trk('tractogram_EuDX.trk', 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft.to_vox()\n",
    "streamlines = sft.streamlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "from dipy.viz import window, actor, colormap\n",
    "\n",
    "# Prepare display objects\n",
    "# streamlines_actor = actor.line(streamlines, colormap.line_colors(streamlines))\n",
    "streamlines_actor = actor.line(streamlines)\n",
    "\n",
    "# Create 3D display\n",
    "scene = window.Scene()\n",
    "\n",
    "# Create the directory to save the results\n",
    "out_dir = '../../data/ds000221/derivatives/dwi/tractography/sub-%s/ses-01/dwi/' % subj\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "det_tractogram_eudx_scene_arr = window.snapshot(\n",
    "    scene,\n",
    "    fname=os.path.join(out_dir, 'tractogram_EuDX.png'),\n",
    "    size=(800, 800), offscreen=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Show the image\n",
    "fig, axes = plt.subplots()\n",
    "axes.imshow(det_tractogram_eudx_scene_arr, origin=\"lower\")\n",
    "axes.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
